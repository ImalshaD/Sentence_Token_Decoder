{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adopt import ADOPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_num_output(text):\n",
    "    match = re.search(r'(?<=The answer is:\\s).*$', text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"data_cache\"\n",
    "model_dir = \"model_cache\"\n",
    "ds = load_dataset(\"meta-math/MetaMathQA\", cache_dir=cache_dir)\n",
    "sen_ds = load_dataset(\"sentence-transformers/wikipedia-en-sentences\",cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ds['train']) \n",
    "sen_df = sen_ds['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>query</th>\n",
       "      <th>original_question</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>Gracie and Joe are choosing numbers on the com...</td>\n",
       "      <td>Gracie and Joe are choosing numbers on the com...</td>\n",
       "      <td>The distance between two points $(x_1,y_1)$ an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM_Rephrased</td>\n",
       "      <td>What is the total cost of purchasing equipment...</td>\n",
       "      <td>The treasurer of a football team must buy equi...</td>\n",
       "      <td>Each player requires a $25 jersey, a $15.20 pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM_SV</td>\n",
       "      <td>Diego baked 12 cakes for his sister's birthday...</td>\n",
       "      <td>Diego baked 12 cakes for his sister's birthday...</td>\n",
       "      <td>To solve this problem, we need to determine th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>Convert $10101_3$ to a base 10 integer.</td>\n",
       "      <td>Convert $10101_3$ to a base 10 integer.</td>\n",
       "      <td>$10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM_FOBAR</td>\n",
       "      <td>Sue works in a factory and every 30 minutes, a...</td>\n",
       "      <td>Sue works in a factory and every 30 minutes, a...</td>\n",
       "      <td>We know that every 30 minutes, a machine produ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type                                              query  \\\n",
       "0    MATH_AnsAug  Gracie and Joe are choosing numbers on the com...   \n",
       "1  GSM_Rephrased  What is the total cost of purchasing equipment...   \n",
       "2         GSM_SV  Diego baked 12 cakes for his sister's birthday...   \n",
       "3    MATH_AnsAug            Convert $10101_3$ to a base 10 integer.   \n",
       "4      GSM_FOBAR  Sue works in a factory and every 30 minutes, a...   \n",
       "\n",
       "                                   original_question  \\\n",
       "0  Gracie and Joe are choosing numbers on the com...   \n",
       "1  The treasurer of a football team must buy equi...   \n",
       "2  Diego baked 12 cakes for his sister's birthday...   \n",
       "3            Convert $10101_3$ to a base 10 integer.   \n",
       "4  Sue works in a factory and every 30 minutes, a...   \n",
       "\n",
       "                                            response  \n",
       "0  The distance between two points $(x_1,y_1)$ an...  \n",
       "1  Each player requires a $25 jersey, a $15.20 pa...  \n",
       "2  To solve this problem, we need to determine th...  \n",
       "3  $10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...  \n",
       "4  We know that every 30 minutes, a machine produ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The film stars M. G. Ramachandran, Latha, Anja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naarda plenirena is a species of moth in the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sponsored by the American Federation of Labor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Since that election the Belfast Corporation Ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was also included on their Best of Volume 1.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0  The film stars M. G. Ramachandran, Latha, Anja...\n",
       "1  Naarda plenirena is a species of moth in the f...\n",
       "2  Sponsored by the American Federation of Labor ...\n",
       "3  Since that election the Belfast Corporation Ac...\n",
       "4    It was also included on their Best of Volume 1."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Numerical_output']= df['response'].apply(extract_num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>query</th>\n",
       "      <th>original_question</th>\n",
       "      <th>response</th>\n",
       "      <th>Numerical_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>Gracie and Joe are choosing numbers on the com...</td>\n",
       "      <td>Gracie and Joe are choosing numbers on the com...</td>\n",
       "      <td>The distance between two points $(x_1,y_1)$ an...</td>\n",
       "      <td>\\sqrt{5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM_Rephrased</td>\n",
       "      <td>What is the total cost of purchasing equipment...</td>\n",
       "      <td>The treasurer of a football team must buy equi...</td>\n",
       "      <td>Each player requires a $25 jersey, a $15.20 pa...</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM_SV</td>\n",
       "      <td>Diego baked 12 cakes for his sister's birthday...</td>\n",
       "      <td>Diego baked 12 cakes for his sister's birthday...</td>\n",
       "      <td>To solve this problem, we need to determine th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>Convert $10101_3$ to a base 10 integer.</td>\n",
       "      <td>Convert $10101_3$ to a base 10 integer.</td>\n",
       "      <td>$10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM_FOBAR</td>\n",
       "      <td>Sue works in a factory and every 30 minutes, a...</td>\n",
       "      <td>Sue works in a factory and every 30 minutes, a...</td>\n",
       "      <td>We know that every 30 minutes, a machine produ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394995</th>\n",
       "      <td>GSM_FOBAR</td>\n",
       "      <td>Yesterday, David and William were invited to a...</td>\n",
       "      <td>Yesterday, David and William were invited to a...</td>\n",
       "      <td>David broke 2 glasses.\\nHis friend William bro...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394996</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>Suppose $\\sin N = \\frac{2}{3}$ in the diagram ...</td>\n",
       "      <td>Suppose $\\sin N = \\frac{2}{3}$ in the diagram ...</td>\n",
       "      <td>We can use the Pythagorean Theorem to find $LN...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394997</th>\n",
       "      <td>GSM_FOBAR</td>\n",
       "      <td>Jeff orders a Halloween costume.  He has to pu...</td>\n",
       "      <td>Jeff orders a Halloween costume.  He has to pu...</td>\n",
       "      <td>The costume cost 40% more than last year's cos...</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394998</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>The average age of the 10 females in a choir i...</td>\n",
       "      <td>The average age of the 10 females in a choir i...</td>\n",
       "      <td>The sum of the ages of the 10 females is $10 \\...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394999</th>\n",
       "      <td>GSM_AnsAug</td>\n",
       "      <td>In a shipping container, there are 10 crates. ...</td>\n",
       "      <td>In a shipping container, there are 10 crates. ...</td>\n",
       "      <td>There are 10 crates in the shipping container....</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 type                                              query  \\\n",
       "0         MATH_AnsAug  Gracie and Joe are choosing numbers on the com...   \n",
       "1       GSM_Rephrased  What is the total cost of purchasing equipment...   \n",
       "2              GSM_SV  Diego baked 12 cakes for his sister's birthday...   \n",
       "3         MATH_AnsAug            Convert $10101_3$ to a base 10 integer.   \n",
       "4           GSM_FOBAR  Sue works in a factory and every 30 minutes, a...   \n",
       "...               ...                                                ...   \n",
       "394995      GSM_FOBAR  Yesterday, David and William were invited to a...   \n",
       "394996    MATH_AnsAug  Suppose $\\sin N = \\frac{2}{3}$ in the diagram ...   \n",
       "394997      GSM_FOBAR  Jeff orders a Halloween costume.  He has to pu...   \n",
       "394998    MATH_AnsAug  The average age of the 10 females in a choir i...   \n",
       "394999     GSM_AnsAug  In a shipping container, there are 10 crates. ...   \n",
       "\n",
       "                                        original_question  \\\n",
       "0       Gracie and Joe are choosing numbers on the com...   \n",
       "1       The treasurer of a football team must buy equi...   \n",
       "2       Diego baked 12 cakes for his sister's birthday...   \n",
       "3                 Convert $10101_3$ to a base 10 integer.   \n",
       "4       Sue works in a factory and every 30 minutes, a...   \n",
       "...                                                   ...   \n",
       "394995  Yesterday, David and William were invited to a...   \n",
       "394996  Suppose $\\sin N = \\frac{2}{3}$ in the diagram ...   \n",
       "394997  Jeff orders a Halloween costume.  He has to pu...   \n",
       "394998  The average age of the 10 females in a choir i...   \n",
       "394999  In a shipping container, there are 10 crates. ...   \n",
       "\n",
       "                                                 response Numerical_output  \n",
       "0       The distance between two points $(x_1,y_1)$ an...         \\sqrt{5}  \n",
       "1       Each player requires a $25 jersey, a $15.20 pa...              752  \n",
       "2       To solve this problem, we need to determine th...                1  \n",
       "3       $10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...               91  \n",
       "4       We know that every 30 minutes, a machine produ...                1  \n",
       "...                                                   ...              ...  \n",
       "394995  David broke 2 glasses.\\nHis friend William bro...                4  \n",
       "394996  We can use the Pythagorean Theorem to find $LN...               24  \n",
       "394997  The costume cost 40% more than last year's cos...              250  \n",
       "394998  The sum of the ages of the 10 females is $10 \\...               33  \n",
       "394999  There are 10 crates in the shipping container....               60  \n",
       "\n",
       "[395000 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type                 0\n",
       "query                0\n",
       "original_question    0\n",
       "response             0\n",
       "Numerical_output     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Qwen2ForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and encoder-only model\n",
    "tokenizer_lm = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-Math-1.5B-Instruct\", cache_dir=\"model_cache\", padding_side='left')\n",
    "model_lm = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-Math-1.5B-Instruct\", cache_dir=\"model_cache\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "max_tokens = 100\n",
    "embedding_lenght = 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=1\n",
    "split_size = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_query = df[\"query\"]\n",
    "sen_train = sen_df['sentence'].sample(n=split_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = X_train_query.to_numpy()\n",
    "sen_array = sen_train.to_numpy()\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train_math, X_test = train_test_split(data_array, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([X_train_math, sen_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(X_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model: nn.Module):\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    non_trainable_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "    return trainable_params, non_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_embedding_layer=model_lm.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qwen_embeddings(texts):\n",
    "    template = \"<|im_start|>{text}<|im_end|>\"\n",
    "    texts = [template.format(text=text) for text in texts]\n",
    "    tokens = tokenizer_lm(\n",
    "            texts,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=100\n",
    "        ).to(device)\n",
    "    with torch.no_grad():\n",
    "        embeddings = qwen_embedding_layer(tokens.input_ids)\n",
    "    return embeddings, tokens.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_losses(criteria, outputs, targets, target_attention_mask, weight):\n",
    "    pad_attention_mask = 1-target_attention_mask\n",
    "\n",
    "    attention_targets = targets * target_attention_mask.unsqueeze(-1)\n",
    "    pad_targets = targets * pad_attention_mask.unsqueeze(-1)\n",
    "\n",
    "    attention_outputs = outputs * target_attention_mask.unsqueeze(-1)\n",
    "    pad_outputs = outputs * pad_attention_mask.unsqueeze(-1)\n",
    "\n",
    "    attention_loss = criteria(attention_outputs, attention_targets)\n",
    "    pad_loss = criteria(pad_outputs, pad_targets)\n",
    "\n",
    "    weighted_loss = attention_loss * weight + pad_loss * (1-weight)\n",
    "\n",
    "    return weighted_loss, attention_loss, pad_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, model, optimizer, loss, path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, \"checkpoints/\"+path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with GPU support\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20, warm_ups=5, w=0.9):\n",
    "    \n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    best_val_loss = np.inf\n",
    "    \n",
    "    # Move the model to the selected device (GPU or CPU)\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs+2*warm_ups):\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0.0\n",
    "        train_attention_loss = 0.0\n",
    "        train_pad_loss = 0.0\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_attention_loss = 0.0\n",
    "        val_pad_loss = 0.0\n",
    "        \n",
    "        model_saved_at_epoch = False\n",
    "\n",
    "        warm_up = epoch < warm_ups\n",
    "        warm_downs = epoch >= (num_epochs - warm_ups)\n",
    "\n",
    "        if not(warm_up or warm_downs):\n",
    "            model.freeze_wrapper()\n",
    "        else:\n",
    "            model.freeze_wrapper(False)\n",
    "        \n",
    "        # Training phase\n",
    "        for inputs in tqdm(train_loader, desc = f'epoch_{epoch+1}/{num_epochs}_warm_up_{warm_up}_warm_down_{warm_downs}'):\n",
    "            \n",
    "            embeddings, attention_mask = get_qwen_embeddings(inputs)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            \n",
    "            outputs = model(embeddings,embeddings, attention_mask=attention_mask, short_circuit=warm_up)\n",
    "            weighted_loss, attention_loss, pad_loss = get_losses(criterion, outputs, embeddings, attention_mask, w)\n",
    "\n",
    "            if torch.isnan(weighted_loss) or torch.isinf(weighted_loss):\n",
    "                print(f\"Numerical instability detected in training. Skipping this batch.\")\n",
    "                continue\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            weighted_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += weighted_loss.item() * embeddings.size(0)  # Accumulate training loss\n",
    "            train_attention_loss += attention_loss.item() * embeddings.size(0)\n",
    "            train_pad_loss += pad_loss.item() * embeddings.size(0)\n",
    "            \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs in tqdm(val_loader):\n",
    "                embeddings, attention_mask = get_qwen_embeddings(inputs)\n",
    "\n",
    "                outputs = model(embeddings,embeddings, attention_mask=attention_mask, short_circuit=warm_up)\n",
    "                weighted_loss, attention_loss, pad_loss = get_losses(criterion, outputs, embeddings, attention_mask, w)\n",
    "\n",
    "                val_loss += weighted_loss.item() * embeddings.size(0)  # Accumulate validation loss\n",
    "                val_attention_loss += attention_loss.item() * embeddings.size(0)\n",
    "                val_pad_loss += pad_loss.item() * embeddings.size(0)\n",
    "                \n",
    "        \n",
    "        # Calculate average losses\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_attention_loss /= len(train_loader.dataset)\n",
    "        train_pad_loss /= len(train_loader.dataset)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_attention_loss /= len(val_loader.dataset)\n",
    "        val_pad_loss /= len(val_loader.dataset)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_checkpoint(epoch, model, optimizer, best_val_loss, \"best_model.pth\")\n",
    "            print(f\"Best model saved with loss: {best_val_loss:.7f} at epoch {epoch+1}/{num_epochs+2*warm_ups} warm_up_{warm_up} warm_down_{warm_downs}\")\n",
    "            model_saved_at_epoch = True\n",
    "        \n",
    "        # Print losses\n",
    "        log_line = f\"Epoch {epoch+1}/{num_epochs+2*warm_ups}, Train Loss: {train_loss:.7f}, Val Loss: {val_loss:.7f}, Train Attention Loss: {train_attention_loss:.7f}, Val Attention Loss: {val_attention_loss:.7f}, Train Pad Loss: {train_pad_loss:.7f}, Val Pad Loss: {val_pad_loss:.7f}\"\n",
    "        print(log_line)\n",
    "        with open(\"logs/logs.txt\", \"a\") as log_file:\n",
    "            log_file.write(log_line + f\" model_saved {model_saved_at_epoch}\"+ \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearAutoencoder, self).__init__()\n",
    "        \n",
    "        # Flatten the input\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(100 * 1536, 1024*2),  # Input size: 200*1536, Output size: 1024\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(1024*2,1024),\n",
    "            # nn.LeakyReLU(0.001),\n",
    "            # nn.Linear(1024*2, 1024)             # Bottleneck size: 64\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            # nn.Linear(1024, 1024*2),             # Input size: 64, Output size: 256\n",
    "            # nn.LeakyReLU(0.001),\n",
    "            nn.Linear(1024,1024*2),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(1024*2, 100 * 1536),    # Output size: 200*1536\n",
    "            nn.Tanh()                  #\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)  # Flatten the input tensor\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded.view(-1, 100, 1536)  # Reshape to original image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 2, kernel_size=3, stride=2, padding=1),  # Output: (16, 100, 768)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 4, kernel_size=3, stride=2, padding=1),  # Output: (32, 50, 384)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 8, kernel_size=3, stride=2, padding=1),  # Output: (64, 25, 192)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 1, kernel_size=3, stride=2, padding=1), # Output: (128, 13, 96)\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 8, kernel_size=3, stride=2, padding=1, output_padding=(1, 1)),  # Output: (64, 25, 192)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 4, kernel_size=3, stride=2, padding=1, output_padding=(1, 1)),  # Output: (32, 50, 384)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(4, 2, kernel_size=3, stride=2, padding=1, output_padding=(1, 1)),  # Output: (16, 100, 768)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(2, 1, kernel_size=3, stride=2, padding=1, output_padding=(1, 1)),   # Output: (1, 200, 1536)\n",
    "            nn.Tanh()  # Output between -1 and 1 for normalized inputs\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add channel dimension: shape becomes [batch_size, 1, 200, 1536]\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        # Encoder\n",
    "        encoded = self.encoder(x)\n",
    "        \n",
    "        # Decoder\n",
    "        decoded = self.decoder(encoded)\n",
    "        \n",
    "        # Remove channel dimension to match the original input shape: [batch_size, 200, 1536]\n",
    "        decoded = decoded.squeeze(1)\n",
    "        \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1dAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv1dAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            # First layer to reduce to (100, 800)\n",
    "            nn.Conv1d(in_channels=1536, out_channels=1536//2, kernel_size=1),\n",
    "            nn.BatchNorm1d(1536//2),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Conv1d(in_channels=1536//2, out_channels=1536//4, kernel_size=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            # Second layer to reduce to (100, 100)\n",
    "            nn.Conv1d(in_channels=1536//4, out_channels=200, kernel_size=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            # First layer to expand back to (100, 800)\n",
    "            nn.ConvTranspose1d(in_channels=200, out_channels=1536//4, kernel_size=1),\n",
    "            nn.BatchNorm1d(1536//4),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.ConvTranspose1d(in_channels=1536//4, out_channels=1536//2, kernel_size=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            # Second layer to expand back to (100, 1536)\n",
    "            nn.ConvTranspose1d(in_channels=1536//2, out_channels=1536, kernel_size=1),\n",
    "            nn.Tanh()  # Use Tanh to output values in the range [-1, 1]\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(100*200, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 100*200)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Transpose to (batch_size, in_channels, sequence_length)\n",
    "        x = x.transpose(1, 2)  # Shape becomes (batch_size, 1536, 100)\n",
    "        \n",
    "        # Encode\n",
    "        encoded = self.encoder(x)  # Shape becomes (batch_size, 100, 100)\n",
    "\n",
    "        encoded_flatten = self.flatten(encoded)\n",
    "\n",
    "        bottle_neck = self.fc1(encoded_flatten)\n",
    "\n",
    "        decoded_fc = self.fc2(bottle_neck)\n",
    "\n",
    "        encoded = decoded_fc.view(-1, 200, 100)\n",
    "        \n",
    "        # Decode\n",
    "        decoded = self.decoder(encoded)  # Shape becomes (batch_size, 1536, 100)\n",
    "        \n",
    "        # Transpose back to (batch_size, sequence_length, feature_dimension)\n",
    "        decoded = decoded.transpose(1, 2)  # Final shape (batch_size, 100, 1536)\n",
    "        \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "    \n",
    "    def forward(self, x, attention_mask=None):\n",
    "        if attention_mask is not None:\n",
    "            x = x* attention_mask.unsqueeze(-1)\n",
    "        # x shape: (batch_size, seq_len, input_size)\n",
    "        _, (_, cell) = self.lstm(x)\n",
    "        # cell shape: (num_layers, batch_size, hidden_size)\n",
    "        return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, num_layers, dropout):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(output_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, prev_state):\n",
    "        # x shape: (batch_size, 1, output_size)\n",
    "        # prev_state is a tuple of (hidden, cell) with shape (num_layers, batch_size, hidden_size)\n",
    "        output, (hidden, cell) = self.lstm(x, prev_state)\n",
    "        # output shape: (batch_size, 1, hidden_size)\n",
    "        # new_cell shape: (num_layers, batch_size, hidden_size)\n",
    "        output = self.fc(output[:, -1, :])\n",
    "        # output shape: (batch_size, output_size)\n",
    "        return output, (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMSeq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, max_tokens, num_layers, dropout=0):\n",
    "        super(LSTMSeq2Seq, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.max_tokens = max_tokens\n",
    "        self.dropout = dropout\n",
    "        self.encoder = LSTMEncoder(self.input_size, self.hidden_size, self.num_layers, self.dropout)\n",
    "        self.decoder = LSTMDecoder(self.output_size, self.hidden_size, self.num_layers, self.dropout)\n",
    "    \n",
    "    def forward(self, source, target=None, attention_mask=None, teacher_forcing_ratio=0.5):\n",
    "        batch_size = source.size(0)\n",
    "        device = source.device\n",
    "\n",
    "        cell = self.encoder(source,attention_mask=attention_mask)\n",
    "\n",
    "        decoder_input = torch.zeros(batch_size, 1, self.output_size, device=device)\n",
    "        hidden = torch.zeros(self.decoder.num_layers, batch_size, self.decoder.hidden_size, device=device)\n",
    "        \n",
    "        outputs = []\n",
    "\n",
    "        # Teacher forcing\n",
    "        for t in range(self.max_tokens):\n",
    "            decoder_output, (hidden, cell) = self.decoder(decoder_input, (hidden, cell))\n",
    "            outputs.append(decoder_output)\n",
    "            \n",
    "            if target is not None:\n",
    "                # Teacher forcing\n",
    "                teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "                decoder_input = target[:, t].unsqueeze(1) if teacher_force else decoder_output.unsqueeze(1)\n",
    "            else:\n",
    "                # Inference mode\n",
    "                decoder_input = decoder_output.unsqueeze(1)\n",
    "        \n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        # outputs shape: (batch_size, target_len, output_size)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedSeqDimReducer(nn.Module):\n",
    "    def __init__(self, input_dim, target_dim, kernel_size=1):\n",
    "        super(AdvancedSeqDimReducer, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding_size = (kernel_size - 1) // 2\n",
    "        \n",
    "        self.reducer = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, input_dim//2, kernel_size=self.kernel_size, padding=self.padding_size),\n",
    "            nn.BatchNorm1d(input_dim//2),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Conv1d(input_dim//2, input_dim//4, kernel_size=self.kernel_size, padding=self.padding_size),\n",
    "            # nn.BatchNorm1d(input_dim//4),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Conv1d(input_dim//4, target_dim, kernel_size=self.kernel_size, padding=self.padding_size),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.reducer(x)\n",
    "        return x.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedSeqReconstructor(nn.Module):\n",
    "    def __init__(self, compressed_dim, target_dim, kernel_size):\n",
    "        super(AdvancedSeqReconstructor, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding_size = (kernel_size - 1) // 2\n",
    "        \n",
    "        self.reconstructor = nn.Sequential(\n",
    "            # First upsampling: compressed_dim → target_dim//4\n",
    "            nn.ConvTranspose1d(compressed_dim, target_dim//4, kernel_size=self.kernel_size, padding=self.padding_size),\n",
    "            nn.BatchNorm1d(target_dim//4),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            # Second upsampling: target_dim//4 → target_dim//2\n",
    "            nn.ConvTranspose1d(target_dim//4, target_dim//2, kernel_size=self.kernel_size, padding=self.padding_size),\n",
    "            # nn.BatchNorm1d(target_dim//2),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            # Final upsampling: target_dim//2 → target_dim\n",
    "            nn.ConvTranspose1d(target_dim//2, target_dim, kernel_size=self.kernel_size, padding=self.padding_size),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Transpose for ConvTranspose1d operation\n",
    "        x = x.transpose(1, 2)  # (batch_size, compressed_dim, sequence_length)\n",
    "        \n",
    "        # Apply reconstruction\n",
    "        x = self.reconstructor(x)\n",
    "        \n",
    "        # Transpose back to original format\n",
    "        return x.transpose(1, 2)  # (batch_size, sequence_length, target_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNWrapper(nn.Module):\n",
    "    def __init__(self, input_dim,compressed_dim, hidden_dim, target_dim, kernel_size, num_layers, max_tokens,dropout=0):\n",
    "        super(CNNWrapper, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = (kernel_size - 1) / 2\n",
    "        self.encoder = AdvancedSeqDimReducer(input_dim,compressed_dim, kernel_size)\n",
    "        self.decoder = AdvancedSeqReconstructor(compressed_dim,target_dim, kernel_size)\n",
    "        self.model = LSTMSeq2Seq(compressed_dim, hidden_dim, compressed_dim, max_tokens, num_layers, dropout)\n",
    "    \n",
    "    def forward(self, source, target=None, attention_mask=None, teacher_forcing_ratio=0.5, short_circuit=False):\n",
    "        if short_circuit:\n",
    "            encoded = self.encoder(source)\n",
    "            decoded = self.decoder(encoded)\n",
    "            return decoded\n",
    "        else:\n",
    "            compressed = self.encoder(source)\n",
    "            if target is not None:\n",
    "                outputs = self.model(compressed, compressed, attention_mask, teacher_forcing_ratio)\n",
    "            else:\n",
    "                outputs = self.model(compressed, None, attention_mask, teacher_forcing_ratio)\n",
    "            reconstructed = self.decoder(outputs)\n",
    "            return reconstructed\n",
    "        \n",
    "    def freeze_wrapper(self,freeze=True):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = not freeze\n",
    "        for param in self.decoder.parameters():\n",
    "            param.requires_grad = not freeze\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNWrapper(1536, 200, 768, 1536, 1, 1, max_tokens, 0)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer (Adam)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9222544, 0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_1/30_warm_up_True_warm_down_False_loss_0.0000000:   0%|          | 0/1286 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_1/30_warm_up_True_warm_down_False_loss_0.0000000:  30%|██▉       | 381/1286 [01:04<02:33,  5.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 53\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, warm_ups, w)\u001b[0m\n\u001b[1;32m     50\u001b[0m weighted_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     51\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 53\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mweighted_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m embeddings\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Accumulate training loss\u001b[39;00m\n\u001b[1;32m     54\u001b[0m train_attention_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m attention_loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m embeddings\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     55\u001b[0m train_pad_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pad_loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m embeddings\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_test = X_test[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If Micah can type 20 words per minute and Isaiah can type 40 words per minute, what is the difference in the number of words they can type in an hour?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(inputs):\n",
    "    encoded_input = tokenizer_lm(\n",
    "        inputs,\n",
    "        max_length=max_tokens,   # Set the fixed length\n",
    "        padding='max_length', # Pad to max length\n",
    "        truncation=True,    # Truncate if longer than max length\n",
    "        return_tensors='pt' # Return as PyTorch tensors\n",
    "    )\n",
    "\n",
    "    # Move input IDs to the appropriate device\n",
    "    input_ids = encoded_input['input_ids'].to(device)\n",
    "    attention_mask = encoded_input['attention_mask'].to(device)\n",
    "    embeddings = model_lm.get_input_embeddings()(input_ids)\n",
    "    return embeddings, attention_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_decoder(inputs):\n",
    "    encoded_input = tokenizer_lm(\n",
    "        inputs,\n",
    "        max_length=max_tokens,   # Set the fixed length\n",
    "        padding='max_length', # Pad to max length\n",
    "        truncation=True,    # Truncate if longer than max length\n",
    "        return_tensors='pt' # Return as PyTorch tensors\n",
    "    )\n",
    "\n",
    "    # Move input IDs to the appropriate device\n",
    "    input_ids = encoded_input['input_ids'].to(device)\n",
    "    attention_mask = encoded_input['attention_mask'].to(device)\n",
    "    embeddings = model_lm.get_input_embeddings()(input_ids)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    # Get the output (predictions)\n",
    "        output = model(embeddings)\n",
    "    return output, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generation(embeddings, attention_mask):\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        outputs= model_lm.generate(\n",
    "            input_ids=None,\n",
    "            inputs_embeds=embeddings,\n",
    "            attention_mask=attention_mask,\n",
    "            pad_token_id=tokenizer_lm.pad_token_id,  # Padding token ID\n",
    "            eos_token_id=tokenizer_lm.eos_token_id,  # End-of-sequence token ID\n",
    "            no_repeat_ngram_size=2,\n",
    "        )\n",
    "    decoded_texts = tokenizer_lm.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return decoded_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_embeddings = get_embeddings(manual_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(original_embeddings[0][0][0]**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03741657386773942"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(0.0014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CNNWrapper.forward() missing 1 required positional argument: 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gen_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanual_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[45], line 17\u001b[0m, in \u001b[0;36mget_embeddings_decoder\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Get the output (predictions)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, attention_mask\n",
      "File \u001b[0;32m~/fyp/Sentence_Token_Decoder/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fyp/Sentence_Token_Decoder/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: CNNWrapper.forward() missing 1 required positional argument: 'target'"
     ]
    }
   ],
   "source": [
    "gen_embeddings = get_embeddings_decoder(manual_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0014, device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gen_embeddings[0][0][0]**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" To determine the difference in the number of words Micah and Isaiah can type in an hour, we need to calculate the words each can produce in that time and then find the absolute difference between these two values.\\n\\n1. Calculate the total number_of_words Miciah can types in one hour.\\n2. Similarly, calculate for Isaiah.\\n3. Find the positive difference of the two results.\\n\\nLet's do this step-by-step using Python code.\\n```python\\n# Constants\\nmicah_typing_speed = 20  # words per minute\\nisaiah_typicing_speed   =   40   #  words  per  minute\\n\\n# Time in minutes\\ntime_in_minutes =    60    # one  hour\\n\\nmiciah_total_words = micahTypingSpeed * time_inMinutes\\nisiahTotalWords = isaiahTypicingSpeed  *  timeInMinutes\\n\\ndifference = abs(micahTotalWord - isiahtotalWord)\\nprint(difference)\\n```\\n```output\\nNameError: name 'micAHTypiIngSpeed' is not defined\\n``\\nIt seems there was a typo in variable names. Let's correct it and run the code again.\\n```\\n\\nReach max function call limit.\"]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_generation(*original_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" To find the difference in the number of words they can type in an hour, we first need to calculate the total number each can write in 60 minutes.\\n\\nFor John, who can make 20 words per minute, the calculation is:\\n2 * 10 * (6 * x) = 300\\n\\nFor Jordan, with a rate of 40 to 50, let's use the average rate for simplicity:\\n(45 + 75) / 90 = (4 * y) + (5 * z)\\n\\nSolving for y and z, which represent the time in minutes Jordan spends at each rate, gives us:\\ny = z = x\\n\\nSince Jordan's average time is 0.5 minutes, Jordan can complete 80% of the words in one hour.\\n\\nNow, to find out how many more words Jordan types than John in a minute:\\n48 -   = ?\\n\\nTo find how much more Jordan writes in total in that hour:\\n8 * [4 - (2/3)] = [8/15] * words\\n\\nTherefore, in terms of total words, John types  [24/55], and Jordan  [(8*12)/11] more than him in each hour.\"]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_generation(gen_embeddings[0],gen_embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" To determine the difference in the number of words Micah and Isaiah can type in an hour, we need to calculate the words each can produce in that time and then find the absolute difference between these two values.\\n\\n1. Calculate the total number_of_words Miciah can types in one hour.\\n2. Similarly, calculate for Isaiah.\\n3. Find the positive difference of the two results.\\n\\nLet's do this step-by-step using Python code.\\n```python\\n# Constants\\nmicah_typing_speed = 20  # words per minute\\nisaiah_typicing_speed   =   40   #  words  per  minute\\n\\n# Time in minutes\\ntime_in_minutes =    60    # one  hour\\n\\nmiciah_total_words = micahTypingSpeed * time_inMinutes\\nisiahTotalWords = isaiahTypicingSpeed  *  timeInMinutes\\n\\ndifference = abs(micahTotalWord - isiahtotalWord)\\nprint(difference)\\n```\\n```output\\nNameError: name 'micAHTypiIngSpeed' is not defined\\n``\\nIt seems there was a typo in variable names. Let's correct it and run the code again.\\n```\\n\\nReach max function call limit.\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_generation(*original_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_generation(*original_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename='model.pth'):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    print(f\"Model saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to AutoEncoderMSE1.pth\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "save_model(model, 'AutoEncoderMSE1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud compute instances stop ndr-a100-spot --zone us-central1-a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
