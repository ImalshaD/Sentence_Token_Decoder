{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_num_output(text):\n",
    "    match = re.search(r'(?<=The answer is:\\s).*$', text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"data_cache\"\n",
    "model_dir = \"model_cache\"\n",
    "ds = load_dataset(\"meta-math/MetaMathQA\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ds['train']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>query</th>\n",
       "      <th>original_question</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>Gracie and Joe are choosing numbers on the com...</td>\n",
       "      <td>Gracie and Joe are choosing numbers on the com...</td>\n",
       "      <td>The distance between two points $(x_1,y_1)$ an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM_Rephrased</td>\n",
       "      <td>What is the total cost of purchasing equipment...</td>\n",
       "      <td>The treasurer of a football team must buy equi...</td>\n",
       "      <td>Each player requires a $25 jersey, a $15.20 pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM_SV</td>\n",
       "      <td>Diego baked 12 cakes for his sister's birthday...</td>\n",
       "      <td>Diego baked 12 cakes for his sister's birthday...</td>\n",
       "      <td>To solve this problem, we need to determine th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>Convert $10101_3$ to a base 10 integer.</td>\n",
       "      <td>Convert $10101_3$ to a base 10 integer.</td>\n",
       "      <td>$10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM_FOBAR</td>\n",
       "      <td>Sue works in a factory and every 30 minutes, a...</td>\n",
       "      <td>Sue works in a factory and every 30 minutes, a...</td>\n",
       "      <td>We know that every 30 minutes, a machine produ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type                                              query  \\\n",
       "0    MATH_AnsAug  Gracie and Joe are choosing numbers on the com...   \n",
       "1  GSM_Rephrased  What is the total cost of purchasing equipment...   \n",
       "2         GSM_SV  Diego baked 12 cakes for his sister's birthday...   \n",
       "3    MATH_AnsAug            Convert $10101_3$ to a base 10 integer.   \n",
       "4      GSM_FOBAR  Sue works in a factory and every 30 minutes, a...   \n",
       "\n",
       "                                   original_question  \\\n",
       "0  Gracie and Joe are choosing numbers on the com...   \n",
       "1  The treasurer of a football team must buy equi...   \n",
       "2  Diego baked 12 cakes for his sister's birthday...   \n",
       "3            Convert $10101_3$ to a base 10 integer.   \n",
       "4  Sue works in a factory and every 30 minutes, a...   \n",
       "\n",
       "                                            response  \n",
       "0  The distance between two points $(x_1,y_1)$ an...  \n",
       "1  Each player requires a $25 jersey, a $15.20 pa...  \n",
       "2  To solve this problem, we need to determine th...  \n",
       "3  $10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...  \n",
       "4  We know that every 30 minutes, a machine produ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Numerical_output']= df['response'].apply(extract_num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>query</th>\n",
       "      <th>original_question</th>\n",
       "      <th>response</th>\n",
       "      <th>Numerical_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>Gracie and Joe are choosing numbers on the com...</td>\n",
       "      <td>Gracie and Joe are choosing numbers on the com...</td>\n",
       "      <td>The distance between two points $(x_1,y_1)$ an...</td>\n",
       "      <td>\\sqrt{5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM_Rephrased</td>\n",
       "      <td>What is the total cost of purchasing equipment...</td>\n",
       "      <td>The treasurer of a football team must buy equi...</td>\n",
       "      <td>Each player requires a $25 jersey, a $15.20 pa...</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM_SV</td>\n",
       "      <td>Diego baked 12 cakes for his sister's birthday...</td>\n",
       "      <td>Diego baked 12 cakes for his sister's birthday...</td>\n",
       "      <td>To solve this problem, we need to determine th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>Convert $10101_3$ to a base 10 integer.</td>\n",
       "      <td>Convert $10101_3$ to a base 10 integer.</td>\n",
       "      <td>$10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM_FOBAR</td>\n",
       "      <td>Sue works in a factory and every 30 minutes, a...</td>\n",
       "      <td>Sue works in a factory and every 30 minutes, a...</td>\n",
       "      <td>We know that every 30 minutes, a machine produ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394995</th>\n",
       "      <td>GSM_FOBAR</td>\n",
       "      <td>Yesterday, David and William were invited to a...</td>\n",
       "      <td>Yesterday, David and William were invited to a...</td>\n",
       "      <td>David broke 2 glasses.\\nHis friend William bro...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394996</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>Suppose $\\sin N = \\frac{2}{3}$ in the diagram ...</td>\n",
       "      <td>Suppose $\\sin N = \\frac{2}{3}$ in the diagram ...</td>\n",
       "      <td>We can use the Pythagorean Theorem to find $LN...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394997</th>\n",
       "      <td>GSM_FOBAR</td>\n",
       "      <td>Jeff orders a Halloween costume.  He has to pu...</td>\n",
       "      <td>Jeff orders a Halloween costume.  He has to pu...</td>\n",
       "      <td>The costume cost 40% more than last year's cos...</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394998</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>The average age of the 10 females in a choir i...</td>\n",
       "      <td>The average age of the 10 females in a choir i...</td>\n",
       "      <td>The sum of the ages of the 10 females is $10 \\...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394999</th>\n",
       "      <td>GSM_AnsAug</td>\n",
       "      <td>In a shipping container, there are 10 crates. ...</td>\n",
       "      <td>In a shipping container, there are 10 crates. ...</td>\n",
       "      <td>There are 10 crates in the shipping container....</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 type                                              query  \\\n",
       "0         MATH_AnsAug  Gracie and Joe are choosing numbers on the com...   \n",
       "1       GSM_Rephrased  What is the total cost of purchasing equipment...   \n",
       "2              GSM_SV  Diego baked 12 cakes for his sister's birthday...   \n",
       "3         MATH_AnsAug            Convert $10101_3$ to a base 10 integer.   \n",
       "4           GSM_FOBAR  Sue works in a factory and every 30 minutes, a...   \n",
       "...               ...                                                ...   \n",
       "394995      GSM_FOBAR  Yesterday, David and William were invited to a...   \n",
       "394996    MATH_AnsAug  Suppose $\\sin N = \\frac{2}{3}$ in the diagram ...   \n",
       "394997      GSM_FOBAR  Jeff orders a Halloween costume.  He has to pu...   \n",
       "394998    MATH_AnsAug  The average age of the 10 females in a choir i...   \n",
       "394999     GSM_AnsAug  In a shipping container, there are 10 crates. ...   \n",
       "\n",
       "                                        original_question  \\\n",
       "0       Gracie and Joe are choosing numbers on the com...   \n",
       "1       The treasurer of a football team must buy equi...   \n",
       "2       Diego baked 12 cakes for his sister's birthday...   \n",
       "3                 Convert $10101_3$ to a base 10 integer.   \n",
       "4       Sue works in a factory and every 30 minutes, a...   \n",
       "...                                                   ...   \n",
       "394995  Yesterday, David and William were invited to a...   \n",
       "394996  Suppose $\\sin N = \\frac{2}{3}$ in the diagram ...   \n",
       "394997  Jeff orders a Halloween costume.  He has to pu...   \n",
       "394998  The average age of the 10 females in a choir i...   \n",
       "394999  In a shipping container, there are 10 crates. ...   \n",
       "\n",
       "                                                 response Numerical_output  \n",
       "0       The distance between two points $(x_1,y_1)$ an...         \\sqrt{5}  \n",
       "1       Each player requires a $25 jersey, a $15.20 pa...              752  \n",
       "2       To solve this problem, we need to determine th...                1  \n",
       "3       $10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...               91  \n",
       "4       We know that every 30 minutes, a machine produ...                1  \n",
       "...                                                   ...              ...  \n",
       "394995  David broke 2 glasses.\\nHis friend William bro...                4  \n",
       "394996  We can use the Pythagorean Theorem to find $LN...               24  \n",
       "394997  The costume cost 40% more than last year's cos...              250  \n",
       "394998  The sum of the ages of the 10 females is $10 \\...               33  \n",
       "394999  There are 10 crates in the shipping container....               60  \n",
       "\n",
       "[395000 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type                 0\n",
       "query                0\n",
       "original_question    0\n",
       "response             0\n",
       "Numerical_output     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Qwen2ForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and encoder-only model\n",
    "tokenizer_lm = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-Math-1.5B\", cache_dir=cache_dir, padding_side='left')\n",
    "model_lm = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-Math-1.5B\", cache_dir=cache_dir).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "max_tokens = 100\n",
    "embedding_lenght = 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=1\n",
    "split_size = 395000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_query = df[\"query\"][split_size*(split-1):split_size*(split)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = X_train_query.to_numpy()\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test = train_test_split(data_array, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(X_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with GPU support\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20):\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Move the model to the selected device (GPU or CPU)\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        # Training phase\n",
    "        for inputs in tqdm(train_loader, desc = f'epoch_{epoch+1}/{num_epochs}'):\n",
    "            \n",
    "            encoded_input = tokenizer_lm(\n",
    "                inputs,\n",
    "                max_length=max_tokens,   # Set the fixed length\n",
    "                padding='max_length', # Pad to max length\n",
    "                truncation=True,    # Truncate if longer than max length\n",
    "                return_tensors='pt' # Return as PyTorch tensors\n",
    "            )\n",
    "\n",
    "            # Move input IDs to the appropriate device\n",
    "            input_ids = encoded_input['input_ids'].to(device)\n",
    "            with torch.no_grad():\n",
    "                embeddings = model_lm.get_input_embeddings()(input_ids)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            \n",
    "            outputs = model(embeddings)\n",
    "            loss = criterion(outputs, embeddings)  # Compare the reconstructed output with the input\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * embeddings.size(0)  # Accumulate training loss\n",
    "            del input_ids, embeddings\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs in val_loader:\n",
    "                encoded_input = tokenizer_lm(\n",
    "                    inputs,\n",
    "                    max_length=max_tokens,   # Set the fixed length\n",
    "                    padding='max_length', # Pad to max length\n",
    "                    truncation=True,    # Truncate if longer than max length\n",
    "                    return_tensors='pt' # Return as PyTorch tensors\n",
    "                )\n",
    "\n",
    "                # Move input IDs to the appropriate device\n",
    "                input_ids = encoded_input['input_ids'].to(device)\n",
    "                embeddings = model_lm.get_input_embeddings()(input_ids)\n",
    "                \n",
    "                outputs = model(embeddings)\n",
    "                loss = criterion(outputs, embeddings)\n",
    "                val_loss += loss.item() * embeddings.size(0)  # Accumulate validation loss\n",
    "                \n",
    "                del input_ids, embeddings\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Calculate average losses\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        \n",
    "        # Print losses\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.7f}, Val Loss: {val_loss:.7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearAutoencoder, self).__init__()\n",
    "        \n",
    "        # Flatten the input\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(100 * 1536, 1024*2),  # Input size: 200*1536, Output size: 1024\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(1024*2,1024),\n",
    "            # nn.LeakyReLU(0.001),\n",
    "            # nn.Linear(1024*2, 1024)             # Bottleneck size: 64\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            # nn.Linear(1024, 1024*2),             # Input size: 64, Output size: 256\n",
    "            # nn.LeakyReLU(0.001),\n",
    "            nn.Linear(1024,1024*2),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(1024*2, 100 * 1536),    # Output size: 200*1536\n",
    "            nn.Tanh()                  #\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)  # Flatten the input tensor\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded.view(-1, 100, 1536)  # Reshape to original image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 2, kernel_size=3, stride=2, padding=1),  # Output: (16, 100, 768)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 4, kernel_size=3, stride=2, padding=1),  # Output: (32, 50, 384)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 8, kernel_size=3, stride=2, padding=1),  # Output: (64, 25, 192)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 1, kernel_size=3, stride=2, padding=1), # Output: (128, 13, 96)\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 8, kernel_size=3, stride=2, padding=1, output_padding=(1, 1)),  # Output: (64, 25, 192)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 4, kernel_size=3, stride=2, padding=1, output_padding=(1, 1)),  # Output: (32, 50, 384)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(4, 2, kernel_size=3, stride=2, padding=1, output_padding=(1, 1)),  # Output: (16, 100, 768)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(2, 1, kernel_size=3, stride=2, padding=1, output_padding=(1, 1)),   # Output: (1, 200, 1536)\n",
    "            nn.Tanh()  # Output between -1 and 1 for normalized inputs\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add channel dimension: shape becomes [batch_size, 1, 200, 1536]\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        # Encoder\n",
    "        encoded = self.encoder(x)\n",
    "        \n",
    "        # Decoder\n",
    "        decoded = self.decoder(encoded)\n",
    "        \n",
    "        # Remove channel dimension to match the original input shape: [batch_size, 200, 1536]\n",
    "        decoded = decoded.squeeze(1)\n",
    "        \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1dAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv1dAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            # First layer to reduce to (100, 800)\n",
    "            nn.Conv1d(in_channels=1536, out_channels=800, kernel_size=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            nn.Conv1d(in_channels=800, out_channels=400, kernel_size=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            # Second layer to reduce to (100, 100)\n",
    "            nn.Conv1d(in_channels=400, out_channels=200, kernel_size=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            # First layer to expand back to (100, 800)\n",
    "            nn.ConvTranspose1d(in_channels=200, out_channels=400, kernel_size=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            nn.ConvTranspose1d(in_channels=400, out_channels=800, kernel_size=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            # Second layer to expand back to (100, 1536)\n",
    "            nn.ConvTranspose1d(in_channels=800, out_channels=1536, kernel_size=1),\n",
    "            nn.Tanh()  # Use Tanh to output values in the range [-1, 1]\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(100*200, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 100*200)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Transpose to (batch_size, in_channels, sequence_length)\n",
    "        x = x.transpose(1, 2)  # Shape becomes (batch_size, 1536, 100)\n",
    "        \n",
    "        # Encode\n",
    "        encoded = self.encoder(x)  # Shape becomes (batch_size, 100, 100)\n",
    "\n",
    "        encoded_flatten = self.flatten(encoded)\n",
    "\n",
    "        bottle_neck = self.fc1(encoded_flatten)\n",
    "\n",
    "        decoded_fc = self.fc2(bottle_neck)\n",
    "\n",
    "        encoded = decoded_fc.view(-1, 200, 100)\n",
    "        \n",
    "        # Decode\n",
    "        decoded = self.decoder(encoded)  # Shape becomes (batch_size, 1536, 100)\n",
    "        \n",
    "        # Transpose back to (batch_size, sequence_length, feature_dimension)\n",
    "        decoded = decoded.transpose(1, 2)  # Final shape (batch_size, 100, 1536)\n",
    "        \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the autoencoder model\n",
    "model = Conv1dAutoencoder()\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer (Adam)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_1/30:   0%|          | 0/309 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_1/30: 100%|██████████| 309/309 [00:58<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.0004924, Val Loss: 0.0004190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_2/30: 100%|██████████| 309/309 [01:03<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.0003341, Val Loss: 0.0002853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_3/30: 100%|██████████| 309/309 [00:57<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.0002598, Val Loss: 0.0002439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_4/30: 100%|██████████| 309/309 [01:03<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.0002260, Val Loss: 0.0002125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_5/30: 100%|██████████| 309/309 [00:57<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.0001987, Val Loss: 0.0001993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_6/30: 100%|██████████| 309/309 [01:03<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.0001784, Val Loss: 0.0001702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_7/30: 100%|██████████| 309/309 [00:57<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.0001665, Val Loss: 0.0001572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_8/30: 100%|██████████| 309/309 [01:03<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.0001542, Val Loss: 0.0001658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_9/30: 100%|██████████| 309/309 [00:57<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.0001465, Val Loss: 0.0001419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_10/30: 100%|██████████| 309/309 [01:03<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.0001399, Val Loss: 0.0001370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_11/30: 100%|██████████| 309/309 [00:57<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.0001354, Val Loss: 0.0001312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_12/30: 100%|██████████| 309/309 [01:03<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.0001289, Val Loss: 0.0001260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_13/30: 100%|██████████| 309/309 [00:57<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Loss: 0.0001379, Val Loss: 0.0001233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_14/30: 100%|██████████| 309/309 [01:03<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Loss: 0.0001212, Val Loss: 0.0001183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_15/30: 100%|██████████| 309/309 [00:57<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Loss: 0.0001170, Val Loss: 0.0001152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_16/30: 100%|██████████| 309/309 [01:03<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Loss: 0.0001134, Val Loss: 0.0001133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_17/30: 100%|██████████| 309/309 [00:57<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Loss: 0.0001102, Val Loss: 0.0001076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_18/30: 100%|██████████| 309/309 [01:03<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Loss: 0.0001071, Val Loss: 0.0001054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_19/30: 100%|██████████| 309/309 [00:57<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Loss: 0.0001069, Val Loss: 0.0001030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_20/30: 100%|██████████| 309/309 [01:03<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Loss: 0.0001020, Val Loss: 0.0001010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_21/30: 100%|██████████| 309/309 [00:57<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Loss: 0.0001002, Val Loss: 0.0000993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_22/30: 100%|██████████| 309/309 [01:03<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Loss: 0.0000984, Val Loss: 0.0000978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_23/30: 100%|██████████| 309/309 [00:57<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Loss: 0.0001009, Val Loss: 0.0000951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_24/30: 100%|██████████| 309/309 [01:03<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Loss: 0.0000951, Val Loss: 0.0000938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_25/30: 100%|██████████| 309/309 [00:57<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Loss: 0.0000939, Val Loss: 0.0000936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_26/30: 100%|██████████| 309/309 [01:03<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Loss: 0.0000927, Val Loss: 0.0000913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_27/30: 100%|██████████| 309/309 [00:57<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Loss: 0.0000916, Val Loss: 0.0000909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_28/30: 100%|██████████| 309/309 [01:03<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Loss: 0.0000906, Val Loss: 0.0000899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_29/30: 100%|██████████| 309/309 [00:57<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Loss: 0.0000897, Val Loss: 0.0000883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_30/30: 100%|██████████| 309/309 [01:03<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.0000886, Val Loss: 0.0000876\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_test = X_test[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If Micah can type 20 words per minute and Isaiah can type 40 words per minute, what is the difference in the number of words they can type in an hour?'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(inputs):\n",
    "    encoded_input = tokenizer_lm(\n",
    "        inputs,\n",
    "        max_length=max_tokens,   # Set the fixed length\n",
    "        padding='max_length', # Pad to max length\n",
    "        truncation=True,    # Truncate if longer than max length\n",
    "        return_tensors='pt' # Return as PyTorch tensors\n",
    "    )\n",
    "\n",
    "    # Move input IDs to the appropriate device\n",
    "    input_ids = encoded_input['input_ids'].to(device)\n",
    "    attention_mask = encoded_input['attention_mask'].to(device)\n",
    "    embeddings = model_lm.get_input_embeddings()(input_ids)\n",
    "    return embeddings, attention_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_decoder(inputs):\n",
    "    encoded_input = tokenizer_lm(\n",
    "        inputs,\n",
    "        max_length=max_tokens,   # Set the fixed length\n",
    "        padding='max_length', # Pad to max length\n",
    "        truncation=True,    # Truncate if longer than max length\n",
    "        return_tensors='pt' # Return as PyTorch tensors\n",
    "    )\n",
    "\n",
    "    # Move input IDs to the appropriate device\n",
    "    input_ids = encoded_input['input_ids'].to(device)\n",
    "    attention_mask = encoded_input['attention_mask'].to(device)\n",
    "    embeddings = model_lm.get_input_embeddings()(input_ids)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    # Get the output (predictions)\n",
    "        output = model(embeddings)\n",
    "    return output, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generation(embeddings, attention_mask):\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        outputs= model_lm.generate(\n",
    "            input_ids=None,\n",
    "            inputs_embeds=embeddings,\n",
    "            attention_mask=attention_mask,\n",
    "            pad_token_id=tokenizer_lm.pad_token_id,  # Padding token ID\n",
    "            eos_token_id=tokenizer_lm.eos_token_id,  # End-of-sequence token ID\n",
    "            no_repeat_ngram_size=2,\n",
    "        )\n",
    "    decoded_texts = tokenizer_lm.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return decoded_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_embeddings = get_embeddings(manual_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(original_embeddings[0][0][0]**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03741657386773942"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(0.0014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_embeddings = get_embeddings_decoder(manual_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0014, device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gen_embeddings[0][0][0]**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" To determine the difference in the number of words Micah and Isaiah can type in an hour, we need to calculate the words each can produce in that time and then find the absolute difference between these two values.\\n\\n1. Calculate the total number_of_words Miciah can types in one hour.\\n2. Similarly, calculate for Isaiah.\\n3. Find the positive difference of the two results.\\n\\nLet's do this step-by-step using Python code.\\n```python\\n# Constants\\nmicah_typing_speed = 20  # words per minute\\nisaiah_typicing_speed   =   40   #  words  per  minute\\n\\n# Time in minutes\\ntime_in_minutes =    60    # one  hour\\n\\nmiciah_total_words = micahTypingSpeed * time_inMinutes\\nisiahTotalWords = isaiahTypicingSpeed  *  timeInMinutes\\n\\ndifference = abs(micahTotalWord - isiahtotalWord)\\nprint(difference)\\n```\\n```output\\nNameError: name 'micAHTypiIngSpeed' is not defined\\n``\\nIt seems there was a typo in variable names. Let's correct it and run the code again.\\n```\\n\\nReach max function call limit.\"]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_generation(*original_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" To find the difference in the number of words they can type in an hour, we first need to calculate the total number each can write in 60 minutes.\\n\\nFor John, who can make 20 words per minute, the calculation is:\\n2 * 10 * (6 * x) = 300\\n\\nFor Jordan, with a rate of 40 to 50, let's use the average rate for simplicity:\\n(45 + 75) / 90 = (4 * y) + (5 * z)\\n\\nSolving for y and z, which represent the time in minutes Jordan spends at each rate, gives us:\\ny = z = x\\n\\nSince Jordan's average time is 0.5 minutes, Jordan can complete 80% of the words in one hour.\\n\\nNow, to find out how many more words Jordan types than John in a minute:\\n48 -   = ?\\n\\nTo find how much more Jordan writes in total in that hour:\\n8 * [4 - (2/3)] = [8/15] * words\\n\\nTherefore, in terms of total words, John types  [24/55], and Jordan  [(8*12)/11] more than him in each hour.\"]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_generation(gen_embeddings[0],gen_embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" To determine the difference in the number of words Micah and Isaiah can type in an hour, we need to calculate the words each can produce in that time and then find the absolute difference between these two values.\\n\\n1. Calculate the total number_of_words Miciah can types in one hour.\\n2. Similarly, calculate for Isaiah.\\n3. Find the positive difference of the two results.\\n\\nLet's do this step-by-step using Python code.\\n```python\\n# Constants\\nmicah_typing_speed = 20  # words per minute\\nisaiah_typicing_speed   =   40   #  words  per  minute\\n\\n# Time in minutes\\ntime_in_minutes =    60    # one  hour\\n\\nmiciah_total_words = micahTypingSpeed * time_inMinutes\\nisiahTotalWords = isaiahTypicingSpeed  *  timeInMinutes\\n\\ndifference = abs(micahTotalWord - isiahtotalWord)\\nprint(difference)\\n```\\n```output\\nNameError: name 'micAHTypiIngSpeed' is not defined\\n``\\nIt seems there was a typo in variable names. Let's correct it and run the code again.\\n```\\n\\nReach max function call limit.\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_generation(*original_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_generation(*original_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename='model.pth'):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    print(f\"Model saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to AutoEncoderMSE1.pth\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "save_model(model, 'AutoEncoderMSE1.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
