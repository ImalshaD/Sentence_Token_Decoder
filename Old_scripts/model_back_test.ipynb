{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, PreTrainedModel\n",
    "from transformers.configuration_utils import PretrainedConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPast,\n",
    "    CausalLMOutputWithPast\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_num_output(text):\n",
    "    match = re.search(r'(?<=The answer is:\\s).*$', text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"data_cache\"\n",
    "model_dir = \"model_cache\"\n",
    "ds = load_dataset(\"meta-math/MetaMathQA\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ds['train']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Numerical_output']= df['response'].apply(extract_num_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerOutputs:\n",
    "    def __init__(self, input_ids, attention_mask):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsOutputs:\n",
    "    def __init__(self, input_embeds, attention_mask):\n",
    "        self.input_embeds = input_embeds\n",
    "        self.attention_mask = attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignmentModel(ABC, nn.Module):\n",
    "    input_shape : tuple\n",
    "    output_shape : tuple\n",
    "\n",
    "    def __init__(self,input_shape, output_shape):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    def test(self):\n",
    "        sample_input  = np.zeros(self.input_shape)\n",
    "        output = self.forward(sample_input)\n",
    "        assert output.shape == self.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NITConfig(PretrainedConfig):\n",
    "    modelName = \"NITModel\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 llm_name=\"Qwen/Qwen-1.5B\",\n",
    "                 llm_dim = 1536,\n",
    "                 freez_encoder= True,\n",
    "                 freez_llm = True,\n",
    "                 alignment_class= None,\n",
    "                 max_tokens = 200,\n",
    "                 model_cache_dir = \"model_cache\",\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.llm = llm_name\n",
    "        self.freez_encoder = freez_encoder\n",
    "        self.freez_llm = freez_llm\n",
    "        self.alignment_class = alignment_class\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model_cache =model_cache_dir\n",
    "        self.llm_dim = llm_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NITModel(PreTrainedModel):\n",
    "    tokenizer : AutoTokenizer\n",
    "    llm : AutoModelForCausalLM\n",
    "    alingment_model : AlignmentModel\n",
    "    embeddings: nn.Embedding\n",
    "\n",
    "    def __init__(self, config : NITConfig):\n",
    "        super().__init__(config)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.llm,cache_dir=config.model_cache, padding_side='left')\n",
    "        self.llm = AutoModelForCausalLM.from_pretrained(config.llm,cache_dir=config.model_cache)\n",
    "        self.input_shape = (config.max_tokens,config.llm_dim)\n",
    "        self.output_shape = (config.max_tokens,config.llm_dim)\n",
    "        self.llm_dim = config.llm_dim\n",
    "        self.maxTokens = config.max_tokens\n",
    "        self.alingment_model = config.alignment_class(self.input_shape,self.output_shape)\n",
    "        self.device_me = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # self.llm.to(self.device_me)\n",
    "        # self.alingment_model.to(self.device_me)\n",
    "        self.embeddings = self.llm.get_input_embeddings()\n",
    "\n",
    "        if config.freez_llm:\n",
    "            self.freeze_lm()\n",
    "    \n",
    "    def freeze_lm(self):\n",
    "        for param in self.llm.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_lm(self):\n",
    "        for param in self.llm.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def get_inputIds(self, texts):\n",
    "        encoding = self.tokenizer(\n",
    "            texts,\n",
    "            return_tensors='pt',\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.maxTokens\n",
    "        )\n",
    "        output = TokenizerOutputs(encoding[\"input_ids\"], encoding[\"attention_mask\"])\n",
    "        return output\n",
    "    \n",
    "    def get_embeddings(self, inputs : TokenizerOutputs):\n",
    "        return EmbeddingsOutputs(self.embeddings(inputs.input_ids), inputs.attention_mask)\n",
    "    \n",
    "    def get_embeddings_altered(self, inputs : TokenizerOutputs):\n",
    "        return EmbeddingsOutputs(self.alingment_model(self.get_embeddings(inputs).input_embeds), inputs.attention_mask)\n",
    "    \n",
    "    def original_pipeline(self, texts):\n",
    "        return self.get_embeddings(self.get_inputIds(texts))\n",
    "    \n",
    "    def altered_pipeline(self, texts):\n",
    "        return self.get_embeddings_altered(self.get_inputIds(texts))\n",
    "\n",
    "    def get_outputs(self, embeddings : EmbeddingsOutputs):\n",
    "        return self.llm(\n",
    "            attention_mask=embeddings.attention_mask,\n",
    "            inputs_embeds=embeddings.input_embeds,\n",
    "            return_dict=True\n",
    "        )\n",
    "    \n",
    "    def pipeline_outputs(self, texts, altered = False, grad = False):\n",
    "        if altered:\n",
    "            return self.get_outputs(self.altered_pipeline(texts))\n",
    "        return self.get_outputs(self.original_pipeline(texts))\n",
    "    \n",
    "    def forward(self , texts):\n",
    "        \n",
    "        # TODO: Modify accordingly\n",
    "        batch_size = len(texts)\n",
    "\n",
    "        original_output = self.pipeline_outputs(texts)\n",
    "        altered_outputs = self.pipeline_outputs(texts, altered=True)\n",
    "\n",
    "        original_logits = original_output.logits\n",
    "        altered_logits = altered_outputs.logits\n",
    "\n",
    "        original_prob = F.softmax(original_logits, dim=1)\n",
    "        original_labels = torch.argmax(original_prob, dim=1)\n",
    "\n",
    "        loss = F.cross_entropy(altered_logits,original_labels)\n",
    "        \n",
    "        # loss = rearrange(loss, '(b s) -> b s', b=batch_size)\n",
    "\n",
    "        return CausalLMOutputWithPast(\n",
    "            loss=loss,\n",
    "            logits=altered_logits,\n",
    "            hidden_states=altered_outputs.hidden_states,\n",
    "            attentions=altered_outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "max_tokens = 100\n",
    "embedding_lenght = 1536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=1\n",
    "split_size = 395000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_query = df[\"query\"][split_size*(split-1):split_size*(split)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = X_train_query.to_numpy()\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test = train_test_split(data_array, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(X_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment Model Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAlignmentModel(AlignmentModel):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super().__init__(input_shape, output_shape)\n",
    "        # Calculate flattened dimensions for linear transformation\n",
    "        print(\"Testing Purpose only Don't use this model.\")\n",
    "        input_dim = input_shape[0] * input_shape[1]\n",
    "        output_dim = output_shape[0] * output_shape[1]\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(input_dim, 1000)\n",
    "        self.linear2 = nn.Linear(1000, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten input to match linear layer's expected shape\n",
    "        x = self.flatten(x)\n",
    "        # Pass through linear layer\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        # Reshape output to match output_shape\n",
    "        x = x.view(-1,self.output_shape[0],self.output_shape[1])  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAlignementModel(AlignmentModel):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super().__init__(input_shape, output_shape)\n",
    "        input_dim = input_shape[0] * input_shape[1]\n",
    "        output_dim = output_shape[0] * output_shape[1]\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024*2),  # Input size: 200*1536, Output size: 1024\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(1024*2,1024),\n",
    "            # nn.LeakyReLU(0.001),\n",
    "            # nn.Linear(1024*2, 1024)             # Bottleneck size: 64\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            # nn.Linear(1024, 1024*2),             # Input size: 64, Output size: 256\n",
    "            # nn.LeakyReLU(0.001),\n",
    "            nn.Linear(1024,1024*2),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(1024*2, output_dim),    # Output size: 200*1536\n",
    "            nn.Tanh()                  #\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)  # Flatten the input tensor\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded.view(-1,self.output_shape[0],self.output_shape[1])   # Reshape to original image size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions of save/load Model/Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, loss, filename='checkpoint.pth'):\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint saved at {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, filename='checkpoint.pth'):\n",
    "    if os.path.isfile(filename):\n",
    "        checkpoint = torch.load(filename)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        print(f\"Checkpoint loaded from {filename}, starting at epoch {start_epoch} with loss {loss}\")\n",
    "        return start_epoch, loss\n",
    "    else:\n",
    "        print(f\"No checkpoint found at {filename}\")\n",
    "        return 0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model\n",
    "def save_model(model, filename='model.pth'):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    print(f\"Model saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the model\n",
    "def load_model(model, filename='model.pth'):\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    print(f\"Model loaded from {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1dAutoencoder(AlignmentModel):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super().__init__((100,1536), (100,1536))\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            # First layer to reduce to (100, 800)\n",
    "            nn.Conv1d(in_channels=1536, out_channels=800, kernel_size=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            nn.Conv1d(in_channels=800, out_channels=400, kernel_size=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            # Second layer to reduce to (100, 100)\n",
    "            nn.Conv1d(in_channels=400, out_channels=200, kernel_size=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            # First layer to expand back to (100, 800)\n",
    "            nn.ConvTranspose1d(in_channels=200, out_channels=400, kernel_size=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            nn.ConvTranspose1d(in_channels=400, out_channels=800, kernel_size=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            # Second layer to expand back to (100, 1536)\n",
    "            nn.ConvTranspose1d(in_channels=800, out_channels=1536, kernel_size=1),\n",
    "            nn.Tanh()  # Use Tanh to output values in the range [-1, 1]\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(100*200, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 100*200)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Transpose to (batch_size, in_channels, sequence_length)\n",
    "        x = x.transpose(1, 2)  # Shape becomes (batch_size, 1536, 100)\n",
    "        \n",
    "        # Encode\n",
    "        encoded = self.encoder(x)  # Shape becomes (batch_size, 100, 100)\n",
    "\n",
    "        encoded_flatten = self.flatten(encoded)\n",
    "\n",
    "        bottle_neck = self.fc1(encoded_flatten)\n",
    "\n",
    "        decoded_fc = self.fc2(bottle_neck)\n",
    "\n",
    "        encoded = decoded_fc.view(-1, 200, 100)\n",
    "        \n",
    "        # Decode\n",
    "        decoded = self.decoder(encoded)  # Shape becomes (batch_size, 1536, 100)\n",
    "        \n",
    "        # Transpose back to (batch_size, sequence_length, feature_dimension)\n",
    "        decoded = decoded.transpose(1, 2)  # Final shape (batch_size, 100, 1536)\n",
    "        \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = NITConfig(\n",
    "    llm_name=\"Qwen/Qwen2.5-Math-1.5B\",\n",
    "    llm_dim=embedding_lenght,\n",
    "    freeze_encoder=True,\n",
    "    freez_llm=True,\n",
    "    alignment_class=Conv1dAutoencoder,\n",
    "    max_tokens=max_tokens,\n",
    "    model_cache_dir= model_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nit_model = NITModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NITModelLightning(pl.LightningModule):\n",
    "    def __init__(self, model, lr=1e-3):\n",
    "        super(NITModelLightning, self).__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.model(batch).loss\n",
    "        self.log(\"train_loss\", loss.mean(), on_step=True, on_epoch=True, prog_bar=True, batch_size=batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.model(batch).loss\n",
    "        self.log(\"val_loss\", loss.mean(), on_step=False, on_epoch=True, prog_bar=True, batch_size=batch_size)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NITModelLightning.load_from_checkpoint(\"checkpoints/best-checkpoint.ckpt\", model=nit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [X_test[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How many ways are there to put 4 distinguishable balls into 2 distinguishable boxes?']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NITModel(\n",
       "  (llm): Qwen2ForCausalLM(\n",
       "    (model): Qwen2Model(\n",
       "      (embed_tokens): Embedding(151936, 1536)\n",
       "      (layers): ModuleList(\n",
       "        (0-27): 28 x Qwen2DecoderLayer(\n",
       "          (self_attn): Qwen2SdpaAttention(\n",
       "            (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "            (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            (rotary_emb): Qwen2RotaryEmbedding()\n",
       "          )\n",
       "          (mlp): Qwen2MLP(\n",
       "            (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "            (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "            (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "          (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      (rotary_emb): Qwen2RotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       "  )\n",
       "  (alingment_model): Conv1dAutoencoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Conv1d(1536, 800, kernel_size=(1,), stride=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.1)\n",
       "      (2): Conv1d(800, 400, kernel_size=(1,), stride=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.1)\n",
       "      (4): Conv1d(400, 200, kernel_size=(1,), stride=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): ConvTranspose1d(200, 400, kernel_size=(1,), stride=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.1)\n",
       "      (2): ConvTranspose1d(400, 800, kernel_size=(1,), stride=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.1)\n",
       "      (4): ConvTranspose1d(800, 1536, kernel_size=(1,), stride=(1,))\n",
       "      (5): Tanh()\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc1): Linear(in_features=20000, out_features=2048, bias=True)\n",
       "    (fc2): Linear(in_features=2048, out_features=20000, bias=True)\n",
       "  )\n",
       "  (embeddings): Embedding(151936, 1536)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nit_model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_outputs = model.model.pipeline_outputs(q)\n",
    "altered_outputs = model.model.pipeline_outputs(q,altered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "altered  = nit_model.altered_pipeline(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = nit_model.original_pipeline(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs= nit_model.llm.generate(\n",
    "            input_ids=None,\n",
    "            inputs_embeds=altered.input_embeds,\n",
    "            attention_mask=original.attention_mask,\n",
    "            pad_token_id=nit_model.tokenizer.pad_token_id,  # Padding token ID\n",
    "            eos_token_id=nit_model.tokenizer.eos_token_id,  # End-of-sequence token ID\n",
    "            no_repeat_ngram_size=2,\n",
    "            return_dict=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Finally, we can solve for $x$ by dividing both sides by $-10$:\\n\\n$x = \\\\frac{11}{-20}$\\n\\n$x \\\\approx -0.55$\\n\\nSo, the solution to the equation is $ x = -\\\\frac {13}{2} $ or $ \\\\color{#DF0030}{x =-6.25} $.']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nit_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8663, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(nit_model.altered_pipeline(q).input_embeds, nit_model.original_pipeline(q).input_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15566/3192020436.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from checkpoint.pth, starting at epoch 0 with loss -7550580.039974684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, -7550580.039974684)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load_checkpoint(nit_model,optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
