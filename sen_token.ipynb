{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laser sentence Embeddings to Qwen-math token constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install laser_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laser_encoders import LaserEncoderPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for high precision matrix multiplication in GPUs like A100\n",
    "# Comment out if not using supported GPU\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "number_of_gpus = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M  = 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"laser2qwen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"data_cache\"\n",
    "model_dir = \"model_cache\"\n",
    "checkpoints = 'checkpoints'\n",
    "logs= \"logs\"\n",
    "trained_model = \"trained_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_slice = 5*M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_gpus = 4  \n",
    "max_gpus = min(max_gpus, number_of_gpus)\n",
    "gpus = list(range(max_gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using {max_gpus} GPUs. Gpus: {gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories(*dirs):\n",
    "    for directory in dirs:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"Directories {dirs} ensured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_directories(cache_dir, model_dir, checkpoints, logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_num_output(text):\n",
    "    match = re.search(r'(?<=The answer is:\\s).*$', text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_math_ds = load_dataset(\"meta-math/MetaMathQA\", cache_dir=cache_dir)\n",
    "# Sentence dataset is used to get more english data\n",
    "sen_ds = load_dataset(\"sentence-transformers/wikipedia-en-sentences\",cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_math_df = meta_math_ds['train'].to_pandas()\n",
    "sen_df = sen_ds['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_math_df['num_output'] = meta_math_df['output'].apply(extract_num_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_query = meta_math_df[\"query\"].values\n",
    "sen_query = sen_df[\"sentence\"].sample(n=sentence_slice, random_state=42).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_math, X_test = train_test_split(math_query, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([X_train_math, sen_query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(X_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser = LaserEncoderPipeline(lang=\"eng_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-Math-1.5B-Instruct\", cache_dir=model_dir, padding_side='right')\n",
    "qwen_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-Math-1.5B-Instruct\", cache_dir = model_dir).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_embedding_layer=qwen_model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get sentence Embeddings from Laser\n",
    "def get_laser_embeddings(texts):\n",
    "    return laser.encode_sentences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qwen_embeddings(texts):\n",
    "    template = \"<|im_start|>{text}<|im_end|>\"\n",
    "    texts = [template.format(text=text) for text in texts]\n",
    "    tokens = qwen_tokenizer(\n",
    "            texts,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=max_tokens\n",
    "        ).to(device)\n",
    "    with torch.no_grad():\n",
    "        embeddings = qwen_embedding_layer(tokens.input_ids)\n",
    "    return embeddings, tokens.attention_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing embeddings Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [\"What is 2+2?\", \"What is 3+3?\", \"What is 4+4?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser_test_embeddings = get_laser_embeddings(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser_test_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_test_embeddings = get_qwen_embeddings(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_test_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser_embeddings_shape = laser_test_embeddings.shape[1]\n",
    "qwen_embeddings_shape = qwen_test_embeddings[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser_embeddings_shape, qwen_embeddings_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_losses(criteria, outputs, targets, target_attention_mask, weight, eps=1e-6):\n",
    "    pad_attention_mask = 1-target_attention_mask\n",
    "\n",
    "    attention_norm = (target_attention_mask.sum()+pad_attention_mask.sum())/(target_attention_mask.sum()+eps)\n",
    "    pad_norm = (target_attention_mask.sum()+pad_attention_mask.sum())/(target_attention_mask.sum()+eps)\n",
    "\n",
    "    attention_targets = targets * target_attention_mask.unsqueeze(-1)\n",
    "    pad_targets = targets * pad_attention_mask.unsqueeze(-1)\n",
    "\n",
    "    attention_outputs = outputs * target_attention_mask.unsqueeze(-1)\n",
    "    pad_outputs = outputs * pad_attention_mask.unsqueeze(-1)\n",
    "\n",
    "    attention_loss = criteria(attention_outputs, attention_targets)\n",
    "    pad_loss = criteria(pad_outputs, pad_targets)\n",
    "\n",
    "    weighted_loss = attention_norm*attention_loss * weight + pad_norm*pad_loss * (1-weight)\n",
    "\n",
    "    return weighted_loss, attention_loss, pad_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to save and load Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, model, optimizer, loss, path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, f\"{checkpoints}/{path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, path):\n",
    "    checkpoint = torch.load(f\"{checkpoints}/{path}\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return epoch, model, optimizer, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Freeze and Unfreeze Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeeze_model(model, freeze = True):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = not(freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_qwen(freeze = True):\n",
    "    freeeze_model(qwen_model, freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_laser(freeze = True):\n",
    "    freeeze_model(laser.model, freeze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Decoder Model\n",
    "class lstmDecoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, num_layers, dropout):\n",
    "        super(lstmDecoder, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(output_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, prev_state):\n",
    "        # x shape: (batch_size, 1, output_size)\n",
    "        # prev_state shapes: (num_layers, batch_size, hidden_size)\n",
    "        output, state = self.lstm(x, prev_state)\n",
    "        # output shape: (batch_size, 1, hidden_size)\n",
    "        # state shapes: (num_layers, batch_size, hidden_size)\n",
    "        output = self.fc(output[:, -1, :])\n",
    "        # output shape: (batch_size, output_size)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstmARDecoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, max_tokens,num_layers=1, dropout=0):\n",
    "        super(lstmARDecoder, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.max_tokens = max_tokens\n",
    "        self.decoder = lstmDecoder(output_size, hidden_size, num_layers, dropout)\n",
    "\n",
    "    def forward(self, source, target=None, teacher_forcing_ratio = 0.5):\n",
    "        batch_size = source.size(0)\n",
    "        device = source.device\n",
    "\n",
    "        cell = source\n",
    "\n",
    "        decoder_input = torch.zeros(batch_size, 1, self.output_size, device=device)\n",
    "        hidden = torch.zeros(self.decoder.num_layers, batch_size, self.decoder.hidden_size, device=device)\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        # Teacher forcing\n",
    "        for t in range(self.max_tokens):\n",
    "            decoder_output, (hidden, cell) = self.decoder(decoder_input, (hidden, cell))\n",
    "            outputs.append(decoder_output)\n",
    "            \n",
    "            if target is not None:\n",
    "                # Teacher forcing\n",
    "                teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "                decoder_input = target[:, t].unsqueeze(1) if teacher_force else decoder_output.unsqueeze(1)\n",
    "            else:\n",
    "                # Inference mode\n",
    "                decoder_input = decoder_output.unsqueeze(1)\n",
    "        \n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        # outputs shape: (batch_size, target_len, output_size)\n",
    "        \n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Reconstructor Model\n",
    "class AdvancedSeqReconstructor(nn.Module):\n",
    "    def __init__(self, compressed_dim, target_dim, kernel_size):\n",
    "        super(AdvancedSeqReconstructor, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding_size = (kernel_size - 1) // 2\n",
    "        \n",
    "        self.reconstructor = nn.Sequential(\n",
    "            # First upsampling: compressed_dim → target_dim//4\n",
    "            nn.ConvTranspose1d(compressed_dim, target_dim//4, kernel_size=self.kernel_size, padding=self.padding_size),\n",
    "            nn.BatchNorm1d(target_dim//4),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            # Second upsampling: target_dim//4 → target_dim//2\n",
    "            nn.ConvTranspose1d(target_dim//4, target_dim//2, kernel_size=self.kernel_size, padding=self.padding_size),\n",
    "            # nn.BatchNorm1d(target_dim//2),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            # Final upsampling: target_dim//2 → target_dim\n",
    "            nn.ConvTranspose1d(target_dim//2, target_dim, kernel_size=self.kernel_size, padding=self.padding_size),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Transpose for ConvTranspose1d operation\n",
    "        x = x.transpose(1, 2)  # (batch_size, compressed_dim, sequence_length)\n",
    "        \n",
    "        # Apply reconstruction\n",
    "        x = self.reconstructor(x)\n",
    "        \n",
    "        # Transpose back to original format\n",
    "        return x.transpose(1, 2)  # (batch_size, sequence_length, target_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper_model to wrap the LSTM and CNN models\n",
    "class CNNwrapper(nn.Module):\n",
    "    def __init__(self, sentence_dim, reduced_dim, token_dim, max_tokens, num_lstm_layer = 1, lstm_dropout = 0, cnn_kernel_size = 1):\n",
    "        super(CNNwrapper, self).__init__()\n",
    "        self.lstm_model = lstmARDecoder(sentence_dim, reduced_dim, max_tokens, num_lstm_layer, lstm_dropout)\n",
    "        self.cnn_model = AdvancedSeqReconstructor(reduced_dim, token_dim, cnn_kernel_size)\n",
    "    \n",
    "    def forward(self, source, target=None, teacher_forcing_ratio = 0.5):\n",
    "        lstm_output = self.lstm_model(source, target, teacher_forcing_ratio)\n",
    "        cnn_output = self.cnn_model(lstm_output)\n",
    "        return cnn_output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20, w=0.9):\n",
    "    \n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "\n",
    "    # Move the model to the selected device (GPU or CPU)\n",
    "    model.to(device)\n",
    "\n",
    "    teacher_forcing_ratio = 0.82\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        teacher_forcing_ratio = max(0, teacher_forcing_ratio - 0.02)\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0.0\n",
    "        train_attention_loss = 0.0\n",
    "        train_pad_loss = 0.0\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_attention_loss = 0.0\n",
    "        val_pad_loss = 0.0\n",
    "\n",
    "        model_saved_at_epoch = False\n",
    "\n",
    "        # Training phase\n",
    "        for inputs in tqdm(train_loader, desc=f'epoch_{epoch+1}/{num_epochs}'):\n",
    "\n",
    "            laser_embeddings = get_laser_embeddings(inputs)\n",
    "            embeddings, attention_mask = get_qwen_embeddings(inputs)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(laser_embeddings, embeddings, attention_mask=attention_mask)\n",
    "            weighted_loss, attention_loss, pad_loss = get_losses(criterion, outputs, embeddings, attention_mask, w)\n",
    "\n",
    "            if torch.isnan(weighted_loss) or torch.isinf(weighted_loss):\n",
    "                print(f\"Numerical instability detected in training. Skipping this batch.\")\n",
    "                continue\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            weighted_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += weighted_loss.item() * embeddings.size(0)  # Accumulate training loss\n",
    "            train_attention_loss += attention_loss.item() * embeddings.size(0)\n",
    "            train_pad_loss += pad_loss.item() * embeddings.size(0)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs in tqdm(val_loader):\n",
    "                embeddings, attention_mask = get_qwen_embeddings(inputs)\n",
    "\n",
    "                outputs = model(embeddings, embeddings, attention_mask=attention_mask)\n",
    "                weighted_loss, attention_loss, pad_loss = get_losses(criterion, outputs, embeddings, attention_mask, w)\n",
    "\n",
    "                val_loss += weighted_loss.item() * embeddings.size(0)  # Accumulate validation loss\n",
    "                val_attention_loss += attention_loss.item() * embeddings.size(0)\n",
    "                val_pad_loss += pad_loss.item() * embeddings.size(0)\n",
    "\n",
    "        # Calculate average losses\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_attention_loss /= len(train_loader.dataset)\n",
    "        train_pad_loss /= len(train_loader.dataset)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_attention_loss /= len(val_loader.dataset)\n",
    "        val_pad_loss /= len(val_loader.dataset)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_checkpoint(epoch, model, optimizer, best_val_loss, \"best_model.pth\")\n",
    "            print(f\"Best model saved with loss: {best_val_loss:.7f} at epoch {epoch+1}/{num_epochs}\")\n",
    "            model_saved_at_epoch = True\n",
    "\n",
    "        # Print losses\n",
    "        log_line = (f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.7f}, Val Loss: {val_loss:.7f}, \"\n",
    "                    f\"Train Attention Loss: {train_attention_loss:.7f}, Val Attention Loss: {val_attention_loss:.7f}, \"\n",
    "                    f\"Train Pad Loss: {train_pad_loss:.7f}, Val Pad Loss: {val_pad_loss:.7f}\")\n",
    "        print(log_line)\n",
    "        with open(f\"{logs}/logs.txt\", \"a\") as log_file:\n",
    "            log_file.write(log_line + f\" model_saved {model_saved_at_epoch}\" + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the Model\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to count the number of parameters in the model\n",
    "def count_parameters(model: nn.Module):\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    non_trainable_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "    return trainable_params, non_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = CNNwrapper(laser_embeddings_shape, 100, qwen_embeddings_shape, max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer (Adam)\n",
    "optimizer = torch.optim.AdamW(a_model.parameters(), lr=1e-3, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(a_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(a_model, train_loader, test_loader, criterion, optimizer, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(a_model, f\"{trained_model}/{run_name}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
