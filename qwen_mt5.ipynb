{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NitMultilingualEncoders import NitQwenMathInstruct, NitMT5encoder, NitRobertaencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AlignmentModels import Conv1dAutoencoder, CNN1DRBencoder, CNN1DRBdecoder, LSTMDecoder, TransformerDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.set_device(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_num_output(text):\n",
    "    match = re.search(r'(?<=The answer is:\\s).*$', text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data_cache\"\n",
    "model_dir = \"model_cache\"\n",
    "math_ds = load_dataset(\"meta-math/MetaMathQA\", cache_dir=data_dir)\n",
    "sen_ds = load_dataset(\"sentence-transformers/wikipedia-en-sentences\",cache_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_df = math_ds['train'].to_pandas()\n",
    "sen_df = sen_ds['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>query</th>\n",
       "      <th>original_question</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>Gracie and Joe are choosing numbers on the com...</td>\n",
       "      <td>Gracie and Joe are choosing numbers on the com...</td>\n",
       "      <td>The distance between two points $(x_1,y_1)$ an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM_Rephrased</td>\n",
       "      <td>What is the total cost of purchasing equipment...</td>\n",
       "      <td>The treasurer of a football team must buy equi...</td>\n",
       "      <td>Each player requires a $25 jersey, a $15.20 pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM_SV</td>\n",
       "      <td>Diego baked 12 cakes for his sister's birthday...</td>\n",
       "      <td>Diego baked 12 cakes for his sister's birthday...</td>\n",
       "      <td>To solve this problem, we need to determine th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>Convert $10101_3$ to a base 10 integer.</td>\n",
       "      <td>Convert $10101_3$ to a base 10 integer.</td>\n",
       "      <td>$10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM_FOBAR</td>\n",
       "      <td>Sue works in a factory and every 30 minutes, a...</td>\n",
       "      <td>Sue works in a factory and every 30 minutes, a...</td>\n",
       "      <td>We know that every 30 minutes, a machine produ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type                                              query  \\\n",
       "0    MATH_AnsAug  Gracie and Joe are choosing numbers on the com...   \n",
       "1  GSM_Rephrased  What is the total cost of purchasing equipment...   \n",
       "2         GSM_SV  Diego baked 12 cakes for his sister's birthday...   \n",
       "3    MATH_AnsAug            Convert $10101_3$ to a base 10 integer.   \n",
       "4      GSM_FOBAR  Sue works in a factory and every 30 minutes, a...   \n",
       "\n",
       "                                   original_question  \\\n",
       "0  Gracie and Joe are choosing numbers on the com...   \n",
       "1  The treasurer of a football team must buy equi...   \n",
       "2  Diego baked 12 cakes for his sister's birthday...   \n",
       "3            Convert $10101_3$ to a base 10 integer.   \n",
       "4  Sue works in a factory and every 30 minutes, a...   \n",
       "\n",
       "                                            response  \n",
       "0  The distance between two points $(x_1,y_1)$ an...  \n",
       "1  Each player requires a $25 jersey, a $15.20 pa...  \n",
       "2  To solve this problem, we need to determine th...  \n",
       "3  $10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...  \n",
       "4  We know that every 30 minutes, a machine produ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The film stars M. G. Ramachandran, Latha, Anja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naarda plenirena is a species of moth in the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sponsored by the American Federation of Labor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Since that election the Belfast Corporation Ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was also included on their Best of Volume 1.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0  The film stars M. G. Ramachandran, Latha, Anja...\n",
       "1  Naarda plenirena is a species of moth in the f...\n",
       "2  Sponsored by the American Federation of Labor ...\n",
       "3  Since that election the Belfast Corporation Ac...\n",
       "4    It was also included on their Best of Volume 1."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_df['Numerical_output']= math_df['response'].apply(extract_num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>query</th>\n",
       "      <th>original_question</th>\n",
       "      <th>response</th>\n",
       "      <th>Numerical_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>Gracie and Joe are choosing numbers on the com...</td>\n",
       "      <td>Gracie and Joe are choosing numbers on the com...</td>\n",
       "      <td>The distance between two points $(x_1,y_1)$ an...</td>\n",
       "      <td>\\sqrt{5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM_Rephrased</td>\n",
       "      <td>What is the total cost of purchasing equipment...</td>\n",
       "      <td>The treasurer of a football team must buy equi...</td>\n",
       "      <td>Each player requires a $25 jersey, a $15.20 pa...</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM_SV</td>\n",
       "      <td>Diego baked 12 cakes for his sister's birthday...</td>\n",
       "      <td>Diego baked 12 cakes for his sister's birthday...</td>\n",
       "      <td>To solve this problem, we need to determine th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MATH_AnsAug</td>\n",
       "      <td>Convert $10101_3$ to a base 10 integer.</td>\n",
       "      <td>Convert $10101_3$ to a base 10 integer.</td>\n",
       "      <td>$10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM_FOBAR</td>\n",
       "      <td>Sue works in a factory and every 30 minutes, a...</td>\n",
       "      <td>Sue works in a factory and every 30 minutes, a...</td>\n",
       "      <td>We know that every 30 minutes, a machine produ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type                                              query  \\\n",
       "0    MATH_AnsAug  Gracie and Joe are choosing numbers on the com...   \n",
       "1  GSM_Rephrased  What is the total cost of purchasing equipment...   \n",
       "2         GSM_SV  Diego baked 12 cakes for his sister's birthday...   \n",
       "3    MATH_AnsAug            Convert $10101_3$ to a base 10 integer.   \n",
       "4      GSM_FOBAR  Sue works in a factory and every 30 minutes, a...   \n",
       "\n",
       "                                   original_question  \\\n",
       "0  Gracie and Joe are choosing numbers on the com...   \n",
       "1  The treasurer of a football team must buy equi...   \n",
       "2  Diego baked 12 cakes for his sister's birthday...   \n",
       "3            Convert $10101_3$ to a base 10 integer.   \n",
       "4  Sue works in a factory and every 30 minutes, a...   \n",
       "\n",
       "                                            response Numerical_output  \n",
       "0  The distance between two points $(x_1,y_1)$ an...         \\sqrt{5}  \n",
       "1  Each player requires a $25 jersey, a $15.20 pa...              752  \n",
       "2  To solve this problem, we need to determine th...                1  \n",
       "3  $10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...               91  \n",
       "4  We know that every 30 minutes, a machine produ...                1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type                 0\n",
       "query                0\n",
       "original_question    0\n",
       "response             0\n",
       "Numerical_output     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_train_query = math_df['query']\n",
    "sen_train = sen_df['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_array = math_train_query.to_numpy()\n",
    "sen_array = sen_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_X_train, math_X_test = train_test_split(math_array, test_size=0.2, random_state=42)\n",
    "sen_X_train, sen_X_test = train_test_split(sen_array, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_X_train = np.concatenate((math_X_train, sen_X_train), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_train_loader = DataLoader(math_X_train, batch_size=batch_size, shuffle=True)\n",
    "math_test_loader = DataLoader(math_X_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_train_loader = DataLoader(sen_X_train, batch_size=batch_size, shuffle=True)\n",
    "sen_test_loader = DataLoader(sen_X_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_loader = DataLoader(combined_X_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM and Encoder init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 100\n",
    "padding = \"max_length\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_template = \"<|im_start|>{text}<|im_end|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_ids = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen = NitQwenMathInstruct(cache_dir=model_dir, max_tokens=max_tokens, padding=padding)\n",
    "qwen.setTemplate(qwen_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "rb = NitRobertaencoder(cache_dir=model_dir, max_tokens=max_tokens, padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rb.useDataParellel(gpu_ids)\n",
    "# qwen.useDataParellel(gpu_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_embedding_shape = rb.getEmbedding_shape()\n",
    "qwen_embedding_shape = qwen.getEmbedding_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 768), (100, 1536))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb_embedding_shape, qwen_embedding_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_model = CNN1DRBencoder(rb_embedding_shape, qwen_embedding_shape).to(device)\n",
    "# align_model = TransformerDecoderModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align_model = torch.nn.DataParallel(align_model, device_ids=gpu_ids)\n",
    "align_model = CNN1DRBdecoder(rb_embedding_shape, qwen_embedding_shape).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing NITModels with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [\"how many legs do 400 dogs have, if each dog has 4 legs?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|im_start|>how many legs do 400 dogs have, if each dog has 4 legs?<|im_end|>']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen.applyTemplate(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0175, -0.0038, -0.0056,  ...,  0.0272, -0.0130,  0.0221],\n",
       "         [ 0.0146,  0.0037, -0.0320,  ...,  0.0228, -0.0055,  0.0388],\n",
       "         [ 0.0096, -0.0099,  0.0216,  ...,  0.0417, -0.0024,  0.0309],\n",
       "         ...,\n",
       "         [ 0.0408,  0.0123,  0.0154,  ...,  0.0070,  0.0210, -0.0142],\n",
       "         [ 0.0408,  0.0123,  0.0154,  ...,  0.0070,  0.0210, -0.0142],\n",
       "         [ 0.0408,  0.0123,  0.0154,  ...,  0.0070,  0.0210, -0.0142]]],\n",
       "       device='cuda:0', grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen.get_embeddings_from_text(test_texts).input_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how many legs do  4 0 0 dogs have, if each dog has  4 legs?']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb.applyFormating(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_embs = rb.get_embeddings_from_text(test_texts, pooler_output=True).input_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.0541e-01, -1.5441e-02,  3.4156e-02, -3.2357e-01, -3.1736e-01,\n",
       "        -1.1502e-02,  1.7016e-02, -1.1527e-01,  1.2176e-01, -5.1969e-02,\n",
       "         1.3977e-01, -3.7667e-02, -1.2690e-01, -5.4021e-02, -2.3008e-01,\n",
       "        -6.3373e-02,  2.5877e-02,  7.4595e-02,  2.9210e-01, -7.5359e-02,\n",
       "         8.3690e-04, -4.0202e-03, -1.4141e-02,  4.2198e-01, -6.4608e-02,\n",
       "        -2.4139e-02,  3.6583e-01,  2.3151e-01,  1.1857e-01,  1.0236e-01,\n",
       "        -1.8374e-02, -8.6124e-02,  2.0123e-01,  2.6544e-01, -1.5505e-01,\n",
       "        -3.7288e-02,  1.1489e-03,  1.0705e-01, -7.4041e-02, -1.9716e-01,\n",
       "         3.7293e-02, -2.4643e-01, -1.6754e-01,  3.3686e-01,  1.1518e-01,\n",
       "        -1.9700e-01,  6.7309e-02, -3.0770e-01, -4.5063e-01,  5.0742e-01,\n",
       "        -2.3951e-01,  1.7839e-01, -7.4241e-02,  4.1142e-01,  1.0115e-01,\n",
       "         4.3448e-01, -3.2894e-02,  2.6248e-01, -4.9366e-02, -6.3946e-02,\n",
       "        -3.8566e-02,  1.1402e-01, -6.0186e-02, -3.9147e-01, -1.2564e-01,\n",
       "         1.1212e-01,  1.2654e-01, -1.9248e-01,  2.0440e-01,  1.5134e-01,\n",
       "         1.7360e-01,  1.0777e-01, -4.1952e-01,  5.7044e-02,  3.0072e-02,\n",
       "         1.0503e-01,  1.1883e-01,  1.1607e-03,  2.2453e-01, -2.5859e-01,\n",
       "        -4.2691e-01,  2.2880e-02,  2.0483e-01, -2.9563e-01,  3.4548e-01,\n",
       "        -1.9183e-01, -2.8833e-01,  3.7544e-02,  1.3702e-01,  3.3564e-01,\n",
       "         3.0214e-01,  1.1376e-01, -9.9788e-02, -4.5268e-02, -5.5225e-03,\n",
       "         1.2087e-01,  2.5904e-01,  1.8911e-01, -7.9930e-04, -8.8033e-02,\n",
       "         1.0686e-01, -9.7187e-02,  2.5958e-01,  4.4586e-01,  7.5363e-02,\n",
       "        -1.2056e-01, -1.1655e-01,  1.1590e-01, -4.9945e-02,  5.3512e-01,\n",
       "         3.5191e-02,  8.8880e-02, -2.0149e-01,  2.3693e-01,  5.5932e-02,\n",
       "         1.3825e-01, -2.2218e-01,  2.7449e-01,  3.6699e-01, -5.0742e-02,\n",
       "         1.6868e-02, -2.6215e-01,  2.7174e-01, -2.8569e-02, -3.9183e-01,\n",
       "         3.4692e-02, -1.0577e-01,  3.3899e-01,  2.3756e-01, -2.3667e-01,\n",
       "         5.1124e-01,  3.0392e-04, -1.0582e-01, -4.1341e-01, -1.2355e-01,\n",
       "        -2.3217e-01,  3.7750e-01,  9.4789e-02,  3.4243e-01, -2.2269e-01,\n",
       "         3.2344e-01, -3.5748e-02,  5.1004e-01,  9.0269e-02,  1.2774e-01,\n",
       "        -7.0793e-02,  8.0630e-02,  7.0654e-02,  3.5380e-02, -1.8408e-01,\n",
       "        -9.5638e-02, -3.0129e-04,  2.8176e-01,  1.5957e-01, -4.0137e-01,\n",
       "        -1.4702e-01, -2.5863e-03, -7.0371e-02,  1.8210e-01,  7.1155e-02,\n",
       "        -3.0292e-01, -1.8791e-01, -4.2619e-01,  7.8858e-02,  1.6470e-01,\n",
       "         1.3975e-01, -7.9114e-03, -1.3802e-01, -5.1487e-02, -1.2582e-01,\n",
       "        -2.1883e-01,  1.9635e-02, -7.3232e-02,  1.9699e-01, -8.1920e-02,\n",
       "        -1.8439e-01, -8.6191e-02,  7.0499e-02,  4.2347e-02, -3.5564e-01,\n",
       "        -9.4993e-02, -4.8811e-01,  3.1435e-02,  3.8587e-01, -1.5138e-01,\n",
       "         1.8920e-01,  5.6735e-02,  8.1058e-02,  5.4903e-02,  5.2359e-01,\n",
       "         7.7512e-03, -3.4922e-01,  2.6427e-01,  1.2068e-01, -4.5129e-02,\n",
       "         1.5972e-01,  1.1514e-01,  2.0082e-01, -3.3971e-01, -1.8357e-01,\n",
       "        -1.5284e-01, -3.4253e-02, -3.3339e-01, -7.7005e-02, -2.5081e-02,\n",
       "        -2.4348e-01, -2.5177e-01,  1.4763e-02, -7.7343e-02, -9.2589e-02,\n",
       "         2.8657e-01,  3.2518e-02,  1.7774e-01, -1.5142e-01, -2.3976e-01,\n",
       "        -6.0266e-02, -7.4955e-02,  9.5769e-02,  4.1209e-03, -2.3499e-01,\n",
       "         3.8196e-02,  4.9978e-01,  2.5693e-01, -3.1532e-01, -6.7529e-02,\n",
       "         1.7921e-02, -1.1062e-01, -3.1740e-01, -1.0649e-01, -3.3287e-01,\n",
       "         5.3235e-03, -3.3397e-02, -3.3200e-01,  1.8094e-01,  2.6109e-01,\n",
       "         1.0357e-01,  1.6785e-01, -2.7876e-01, -8.8125e-02, -8.8873e-02,\n",
       "         3.4819e-01, -4.0550e-02,  2.7840e-01, -1.1885e-01, -1.0243e-01,\n",
       "        -1.2205e-01,  1.5906e-01, -2.4114e-01, -4.6460e-02, -1.6839e-01,\n",
       "        -4.9508e-02, -1.8482e-01,  5.0606e-01,  2.4548e-01, -4.3598e-01,\n",
       "         8.8265e-02,  8.9784e-03,  3.1964e-01, -2.1010e-01, -8.8582e-02,\n",
       "         1.0465e-02, -2.7561e-01, -2.2264e-01, -2.0688e-01,  3.7468e-01,\n",
       "        -1.6151e-02, -2.1062e-01, -3.7865e-03, -4.2086e-02, -2.0241e-01,\n",
       "         3.2215e-02,  6.9834e-02, -4.2988e-02, -1.2933e-01,  1.7372e-01,\n",
       "         7.9272e-02,  8.8153e-02, -1.4485e-01,  1.2661e-01,  9.9251e-02,\n",
       "         1.1910e-01, -2.8666e-01,  2.5291e-02, -1.9594e-01, -2.5040e-01,\n",
       "        -1.0727e-01, -1.6965e-01,  3.6354e-02,  2.6370e-01,  6.9148e-02,\n",
       "         3.8511e-02, -6.0606e-02, -1.5233e-02, -1.1953e-01, -4.3803e-01,\n",
       "         2.3870e-01,  1.5114e-01,  1.1707e-01, -1.1715e-01, -2.2229e-02,\n",
       "        -1.4504e-01, -3.2632e-01,  4.4882e-01, -3.0962e-01,  2.1380e-01,\n",
       "        -2.2230e-01,  5.5004e-02,  3.6495e-01,  1.4453e-01,  1.7261e-02,\n",
       "         3.7263e-01,  1.5156e-01, -1.6039e-01, -2.2913e-02,  3.7931e-02,\n",
       "         2.5934e-02,  3.3426e-02,  2.5388e-01,  3.4703e-01, -7.4833e-02,\n",
       "         1.5337e-01, -8.1211e-03,  2.3100e-01, -8.8267e-02, -3.4049e-02,\n",
       "        -2.7136e-03, -3.7842e-01,  2.3041e-01, -1.1378e-01, -1.3046e-01,\n",
       "        -1.0912e-02,  1.4058e-01,  3.9546e-01,  1.1357e-01, -1.5123e-01,\n",
       "        -3.6211e-01, -1.1862e-01,  1.5536e-01, -2.4296e-01, -4.3523e-01,\n",
       "        -5.0609e-02,  2.3065e-01, -1.9725e-01, -5.0311e-01,  1.1800e-01,\n",
       "        -2.0144e-01, -1.0967e-01,  2.7207e-03,  3.2335e-01, -3.4330e-01,\n",
       "         2.6653e-01, -4.0606e-01,  2.0998e-01,  9.2848e-02, -8.1554e-02,\n",
       "        -2.1606e-01, -9.8654e-03,  4.4770e-02,  3.6306e-01, -1.3612e-01,\n",
       "         3.4022e-02, -2.2096e-01, -5.1738e-02, -4.9120e-02, -1.9629e-01,\n",
       "         3.8917e-01, -6.1106e-02,  2.7217e-01, -1.9784e-01, -1.4391e-01,\n",
       "        -3.5162e-01,  1.4961e-01,  5.7266e-02, -1.0490e-01,  3.6392e-03,\n",
       "        -3.9023e-01, -2.3426e-01,  5.5002e-02,  2.0963e-01, -4.5854e-02,\n",
       "        -2.0435e-01, -1.0184e-01,  2.6453e-01, -2.8136e-03,  3.2174e-01,\n",
       "         1.3947e-02, -9.2024e-02, -2.7869e-01,  3.1217e-01, -2.5728e-01,\n",
       "        -1.0526e-01,  9.9707e-02,  1.6999e-01,  1.9099e-01, -3.8148e-02,\n",
       "        -1.0905e-01, -3.4038e-01,  1.7404e-01,  2.0554e-01, -2.4934e-01,\n",
       "        -9.0608e-03,  1.7411e-02, -4.8320e-02,  3.7618e-02, -1.9315e-01,\n",
       "        -1.0553e-01, -1.2244e-01, -6.8496e-02,  1.5429e-01,  3.4777e-02,\n",
       "        -1.5829e-01, -6.1570e-02, -5.9063e-02, -3.9075e-02, -1.8321e-01,\n",
       "         5.9342e-03, -6.5506e-02,  2.0212e-01,  3.5169e-02, -5.8566e-02,\n",
       "        -2.5765e-01,  6.1377e-04,  5.8652e-02, -4.5277e-01,  9.4541e-02,\n",
       "        -3.6579e-01, -1.2655e-01, -4.3687e-02,  2.2263e-01,  2.1798e-01,\n",
       "         2.1914e-02, -4.0891e-01,  4.3398e-01,  9.6142e-02, -1.1138e-01,\n",
       "        -2.9238e-01, -5.4858e-02, -1.0870e-01, -2.8286e-01,  1.3583e-01,\n",
       "         4.4718e-01,  1.5986e-01, -4.1242e-02, -4.7696e-02,  1.8513e-01,\n",
       "         4.1340e-02, -2.2759e-01, -2.6809e-02,  1.3250e-01,  1.3240e-01,\n",
       "        -1.6282e-02, -4.1178e-01, -1.7645e-01, -6.7372e-02,  3.4248e-01,\n",
       "         9.8574e-02,  1.4919e-01, -6.1632e-02,  2.6630e-02, -2.9250e-02,\n",
       "        -1.2489e-02, -1.6093e-02, -4.5703e-01, -2.3209e-01, -2.1224e-01,\n",
       "         1.4354e-01,  3.2090e-02,  2.5678e-01,  2.2717e-01,  2.4878e-01,\n",
       "        -2.0502e-01,  1.1776e-01, -2.7052e-01,  4.7112e-01, -2.5756e-01,\n",
       "         1.1811e-01,  3.9667e-02,  1.1232e-01,  1.1488e-02,  2.1550e-01,\n",
       "         1.5792e-02, -1.3717e-01,  2.0134e-01, -3.9417e-02, -2.1529e-01,\n",
       "         1.0438e-01, -5.8987e-02, -1.5218e-01,  1.5519e-01,  1.8047e-01,\n",
       "         3.9090e-01,  1.6743e-01,  1.8323e-01, -1.9261e-01, -2.3220e-02,\n",
       "        -7.2304e-02, -2.8044e-01, -3.9626e-02,  6.8666e-02, -2.0556e-01,\n",
       "        -3.6171e-01, -1.2489e-01,  7.2539e-02, -6.4595e-02, -1.2885e-01,\n",
       "        -2.4482e-01,  8.9174e-02, -1.5584e-01, -6.5469e-03, -1.2628e-01,\n",
       "        -1.3748e-01, -2.3500e-01,  3.9997e-01,  4.0212e-01, -2.2009e-01,\n",
       "        -1.6468e-01,  1.6491e-01,  2.4769e-02, -1.4489e-01,  8.0567e-02,\n",
       "         6.7471e-02, -3.7510e-01, -1.9556e-01,  4.8502e-01, -4.5979e-01,\n",
       "        -8.5072e-02,  4.1573e-02,  1.8708e-01, -4.7599e-01, -7.0707e-02,\n",
       "         1.4372e-01,  2.0882e-01, -4.0590e-01, -1.6795e-01,  2.5743e-05,\n",
       "         1.9938e-01,  2.8601e-01,  3.4402e-02, -1.3477e-01, -2.4778e-01,\n",
       "        -8.3240e-02,  2.5111e-02,  2.2269e-01,  7.6617e-04,  1.3630e-01,\n",
       "         1.1603e-01,  3.9887e-01, -2.1870e-02, -5.5088e-02,  5.0907e-02,\n",
       "        -1.3791e-01,  3.2602e-01,  2.9231e-01, -1.2699e-01,  1.5516e-01,\n",
       "         1.2017e-02, -1.2360e-01,  2.6946e-01,  1.0500e-01,  4.9398e-02,\n",
       "        -8.5339e-03,  4.9488e-01,  1.7829e-01,  1.8196e-01, -2.0804e-01,\n",
       "         2.1640e-01, -9.6320e-02,  5.5882e-02, -7.5727e-02,  1.7664e-01,\n",
       "        -8.2738e-02, -2.1506e-02, -5.7317e-02, -1.1293e-01,  2.9841e-01,\n",
       "        -2.5664e-01, -7.9863e-02,  3.4910e-01,  3.5212e-01,  1.6774e-01,\n",
       "         7.8050e-02, -1.9921e-01, -6.4686e-02, -5.7928e-02, -3.1250e-01,\n",
       "         4.4532e-01, -2.7981e-01, -5.2052e-01,  4.3519e-01,  5.3468e-01,\n",
       "         3.7577e-03,  3.6779e-02, -1.5410e-01, -4.3165e-02,  7.9212e-04,\n",
       "        -1.5195e-01, -2.6275e-02,  8.9502e-02,  1.9673e-02,  3.8652e-01,\n",
       "        -1.9378e-01,  1.4210e-01, -8.2694e-02,  2.0743e-02,  2.4971e-02,\n",
       "        -6.7191e-02, -1.0362e-01,  2.2372e-01, -9.0952e-02, -1.2619e-01,\n",
       "         5.3611e-02, -2.8713e-01, -1.9941e-01,  8.3886e-02,  5.3884e-02,\n",
       "        -3.7368e-01, -5.9601e-02,  3.7465e-01, -3.3357e-01, -2.8959e-01,\n",
       "        -2.9295e-01, -2.3021e-01, -1.1168e-01,  1.0687e-01,  1.9120e-01,\n",
       "        -8.3499e-03,  2.4665e-01,  2.6154e-01, -1.5004e-01, -2.7902e-01,\n",
       "        -2.9447e-01, -1.7242e-01,  1.1877e-01,  1.1242e-01,  6.5992e-02,\n",
       "        -2.4107e-01, -4.6767e-03, -1.8698e-01, -1.3865e-02, -3.3905e-01,\n",
       "        -1.8068e-03,  9.7948e-02, -3.0176e-01,  1.9716e-01,  7.7624e-02,\n",
       "         3.9887e-01, -7.9491e-02, -9.2244e-02, -1.7298e-01, -1.9016e-01,\n",
       "         4.1367e-03, -1.6900e-02, -3.4469e-01, -1.9139e-01,  2.2608e-01,\n",
       "        -2.2473e-01,  2.2393e-01,  1.0598e-01, -3.7271e-02,  1.0091e-01,\n",
       "        -1.7646e-01,  5.3232e-02, -6.7344e-02, -4.4386e-01,  1.0013e-01,\n",
       "         1.0605e-02, -1.1177e-01,  1.8328e-01,  1.9951e-01,  2.1065e-01,\n",
       "         3.5098e-02, -2.0924e-02, -2.0029e-01,  1.9810e-01,  1.1922e-02,\n",
       "         3.6698e-01, -5.6410e-02,  4.2765e-02,  1.1298e-01,  9.5927e-02,\n",
       "         9.6252e-02,  1.1973e-01,  3.3095e-01,  8.7108e-02, -2.7918e-01,\n",
       "        -2.7012e-01,  6.3294e-02, -2.6115e-01, -5.5346e-01, -1.9626e-01,\n",
       "         2.5566e-01,  2.1307e-02,  1.1102e-01,  2.7272e-01,  1.5090e-01,\n",
       "         1.5837e-01,  5.8202e-02, -6.7868e-02, -1.5734e-01, -1.1539e-01,\n",
       "         1.3027e-01,  6.4552e-02, -3.4588e-02,  4.2513e-02, -3.3358e-02,\n",
       "         5.5577e-02, -1.7266e-01,  5.0131e-01,  8.3823e-04, -1.0112e-01,\n",
       "        -2.7677e-01, -3.6926e-01, -6.9118e-02, -3.3938e-01, -2.1813e-01,\n",
       "         7.1973e-02, -1.2862e-01, -6.8435e-02,  1.4359e-01, -3.0345e-01,\n",
       "        -3.0464e-01,  4.5511e-01,  2.9861e-01,  3.1214e-02, -4.3579e-01,\n",
       "         2.3715e-01,  9.6823e-02,  1.0920e-01, -8.1644e-02, -8.5205e-02,\n",
       "         4.8747e-02, -2.1102e-01,  2.8513e-01,  7.7165e-02, -3.1293e-01,\n",
       "         1.5076e-01,  2.0521e-01,  9.6392e-03,  2.7085e-01,  6.3824e-02,\n",
       "         1.4345e-01, -3.3863e-01, -3.1423e-01,  4.7727e-01, -1.1940e-02,\n",
       "        -1.7491e-01, -9.5546e-02, -7.7735e-02, -4.4181e-01,  2.9750e-01,\n",
       "         6.1238e-02, -1.3066e-01, -4.7354e-03, -3.5632e-01, -3.0079e-01,\n",
       "         1.5815e-01,  1.9869e-02, -4.4699e-01, -2.1426e-01,  3.3005e-01,\n",
       "        -5.6486e-02, -1.7009e-01, -1.3555e-01,  1.1455e-01,  2.0950e-01,\n",
       "         5.3463e-02, -2.2769e-01, -2.0781e-01], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb_embs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, model, optimizer, loss, path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, \"checkpoints/\"+path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train loop\n",
    "def train(model,encoder,llm ,train_loader, test_loader, optimizer, criterion ,epochs=10, scaler=None, clip_value=1.0):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        best_val_loss = np.inf\n",
    "\n",
    "        for batch in tqdm(train_loader, desc = f'epoch_{epoch+1}/{epochs}'):\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                encoder_embedding = encoder.get_embeddings_from_text(batch, pooler_output=True).input_embeds\n",
    "                llm_embedding = llm.get_embeddings_from_text(batch).input_embeds\n",
    "\n",
    "            \n",
    "            # Use AMP for mixed precision if scaler is provided\n",
    "            # with torch.amp.autocast(\"cuda\", enabled=(scaler is not None)):\n",
    "            output = model(encoder_embedding)\n",
    "            loss = criterion(output, llm_embedding)\n",
    "\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(f\"Numerical instability detected in training. Skipping this batch.\")\n",
    "                continue\n",
    "\n",
    "            # Backpropagation with optional scaler\n",
    "            if scaler:\n",
    "                optimizer.zero_grad()\n",
    "                scaler.scale(loss).backward()\n",
    "                # Gradient clipping\n",
    "                scaler.unscale_(optimizer)\n",
    "                clip_grad_norm_(model.parameters(), clip_value)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                clip_grad_norm_(model.parameters(), clip_value)\n",
    "                optimizer.step()\n",
    "                \n",
    "            train_loss += loss.item() * output.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        \n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=\"Validation :\"):\n",
    "                encoder_embedding = encoder.get_embeddings_from_text(batch, pooler_output=True).input_embeds\n",
    "                llm_embedding = llm.get_embeddings_from_text(batch).input_embeds\n",
    "\n",
    "                output = model(encoder_embedding)\n",
    "                loss = criterion(output, llm_embedding)\n",
    "\n",
    "                if torch.isnan(loss) or torch.isinf(loss):\n",
    "                    print(f\"Numerical instability detected in validation. Skipping this batch.\")\n",
    "                    continue\n",
    "\n",
    "                val_loss += loss.item() * output.size(0)\n",
    "                \n",
    "            val_loss /= len(test_loader.dataset)\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                save_checkpoint(epoch, model, optimizer, best_val_loss, \"best_model.pth\")\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.7f}, Val Loss: {val_loss:.7f}\")\n",
    "        with open(\"logs.txt\", \"a\") as log_file:\n",
    "            log_file.write(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.7f}, Val Loss: {val_loss:.7f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(align_model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.MSELoss()\n",
    "# scaler = torch.amp.GradScaler(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(align_model, rb, qwen, sen_train_loader, sen_test_loader, optimizer, criterion, epochs=2, scaler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_1/10: 100%|██████████| 309/309 [01:56<00:00,  2.65it/s]\n",
      "Validation :: 100%|██████████| 78/78 [00:27<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.0004087, Val Loss: 0.0003859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_2/10:   3%|▎         | 8/309 [00:03<02:06,  2.39it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43malign_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqwen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmath_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmath_test_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[46], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, encoder, llm, train_loader, test_loader, optimizer, criterion, epochs, scaler, clip_value)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     13\u001b[0m     encoder_embedding \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mget_embeddings_from_text(batch, pooler_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39minput_embeds\n\u001b[0;32m---> 14\u001b[0m     llm_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embeddings_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minput_embeds\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Use AMP for mixed precision if scaler is provided\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# with torch.amp.autocast(\"cuda\", enabled=(scaler is not None)):\u001b[39;00m\n\u001b[1;32m     19\u001b[0m output \u001b[38;5;241m=\u001b[39m model(encoder_embedding)\n",
      "File \u001b[0;32m~/fyp/Sentence_Token_Decoder/NitMultilingualEncoders/NitEncoder.py:79\u001b[0m, in \u001b[0;36mNitEncoder.get_embeddings_from_text\u001b[0;34m(self, texts, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embeddings_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_embeddings(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_inputIds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/fyp/Sentence_Token_Decoder/NitMultilingualEncoders/NitEncoder.py:72\u001b[0m, in \u001b[0;36mNitEncoder.get_inputIds\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     64\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapplyTemplate(texts)\n\u001b[1;32m     65\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[1;32m     66\u001b[0m     texts,\n\u001b[1;32m     67\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tokens\n\u001b[1;32m     71\u001b[0m )\n\u001b[0;32m---> 72\u001b[0m output \u001b[38;5;241m=\u001b[39m TokenizerOutputs(\u001b[43mencoding\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_me\u001b[49m\u001b[43m)\u001b[49m, encoding[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_me))\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(align_model, rb, qwen, math_train_loader, math_test_loader, optimizer, criterion, epochs=100, scaler=None, clip_value=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename='model.pth'):\n",
    "    torch.save(model.module.state_dict(), filename)\n",
    "    print(f\"Model saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(align_model, filename='qwen_rb_pooler.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
